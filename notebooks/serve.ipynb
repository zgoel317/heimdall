{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D0Ia6X9hZkCO",
        "outputId": "8a0de1b8-34a1-4793-c96a-364bcb3150f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: SPARSIFY_DISABLE_TRITON=1\n",
            "env: OFFLOAD_TRANSCODER=1\n",
            "/content\n",
            "fatal: destination path 'attribute' already exists and is not an empty directory.\n",
            "/content/attribute\n",
            "Already up to date.\n",
            "downloading uv 0.7.13 x86_64-unknown-linux-gnu\n",
            "no checksums to verify\n",
            "installing to /usr/local/bin\n",
            "  uv\n",
            "  uvx\n",
            "everything's installed!\n",
            "\u001b[2mUsing Python 3.11.13 environment at: /usr\u001b[0m\n",
            "\u001b[2K\u001b[2mResolved \u001b[1m161 packages\u001b[0m \u001b[2min 227ms\u001b[0m\u001b[0m\n",
            "\u001b[2K   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m attribution-graph\u001b[2m @ file:///content/attribute\u001b[0m\n",
            "\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m attribution-graph\u001b[2m @ file:///content/attribute\u001b[0m\n",
            "\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m attribution-graph\u001b[2m @ file:///content/attribute\u001b[0m\n",
            "\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m attribution-graph\u001b[2m @ file:///content/attribute\u001b[0m\n",
            "\u001b[2K\u001b[1A      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m attribution-graph\u001b[2m @ file:///content/attribute\u001b[0m\n",
            "\u001b[2K\u001b[2mPrepared \u001b[1m1 package\u001b[0m \u001b[2min 671ms\u001b[0m\u001b[0m\n",
            "\u001b[2mUninstalled \u001b[1m1 package\u001b[0m \u001b[2min 0.55ms\u001b[0m\u001b[0m\n",
            "\u001b[2K\u001b[2mInstalled \u001b[1m1 package\u001b[0m \u001b[2min 0.89ms\u001b[0m\u001b[0m\n",
            " \u001b[33m~\u001b[39m \u001b[1mattribution-graph\u001b[0m\u001b[2m==0.1.0 (from file:///content/attribute)\u001b[0m\n",
            "Collecting triton\n",
            "  Downloading triton-3.3.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.11/dist-packages (from triton) (75.2.0)\n",
            "Downloading triton-3.3.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (155.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.7/155.7 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: triton\n",
            "Successfully installed triton-3.3.1\n"
          ]
        }
      ],
      "source": [
        "#@title Installation\n",
        "from importlib.util import find_spec\n",
        "in_colab = find_spec(\"google.colab\") is not None\n",
        "\n",
        "\n",
        "src = \"\"\"[tool.uv]\n",
        "override-dependencies = [\"\"\"\n",
        "replace_with = \"\"\"\n",
        "    \"torch ; sys_platform == 'never'\",\n",
        "    \"pytorch-triton ; sys_platform == 'never'\",\n",
        "\"\"\"\n",
        "\n",
        "if in_colab:\n",
        "    %env SPARSIFY_DISABLE_TRITON=1\n",
        "    %env OFFLOAD_TRANSCODER=1\n",
        "    %cd /content\n",
        "    !git clone https://github.com/EleutherAI/attribute\n",
        "    %cd attribute\n",
        "    !git pull\n",
        "    pyproject_text = open(\"pyproject.toml\").read()\n",
        "    if src in pyproject_text:\n",
        "        after_src = pyproject_text.index(src) + len(src)\n",
        "        current = pyproject_text[after_src:][:len(replace_with)]\n",
        "        if current != replace_with:\n",
        "            pyproject_text = pyproject_text[:after_src] + replace_with + pyproject_text[after_src:]\n",
        "            open(\"pyproject.toml\", \"w\").write(pyproject_text)\n",
        "    !curl -LsSf https://astral.sh/uv/install.sh | sh\n",
        "    !uv pip install -e .\n",
        "    !pip install triton"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17,
          "referenced_widgets": [
            "d77323599e4048b1b912e2fbb378a4ed",
            "856aeadbde0a473caf3ec3435e6bcb3b",
            "37a4e49355fa45e194c7935489184651",
            "6744bec188814e6c849fb6788004646a",
            "6ac901d815674f21a1dfbe6658465765",
            "13e3f0d317254b64988018d5298f080d",
            "21e13a86ce17455bbcf1f08ff0b3c7d9",
            "48565c1db4ef4deca0154ae3f0a5bfcc",
            "560b81b152c5400b857c4e54ee043bfb",
            "9b1d97b7387e4a2093330d4b734d3832",
            "e392e63fd17d4ca6ae367032b22babb2",
            "cb12395b76f444b8811e6a735d3229e5",
            "fb249295c05742cd849d1f35445268fd",
            "f38f60e36e98470894f46fccc81552d2",
            "26cf19232d764ed29527c29cd0022fad",
            "f199f19bc67b43188ce5ded1ae1f78b1",
            "05b1182539da40fc9ea6cb9b86e35d30",
            "2ab023a61ece409293710460e0afcae2",
            "d0e30f10772a40ac83ece49e4172aca7",
            "38f707461c814d5b8867735220b7849a"
          ]
        },
        "id": "3j_HNwO5ZkCS",
        "outputId": "8ebadcaa-8a81-466c-e116-e3233fcc4d0b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d77323599e4048b1b912e2fbb378a4ed"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "import huggingface_hub\n",
        "huggingface_hub.login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WaTWlxY0ZkCS",
        "outputId": "5d21a3a4-6929-4d06-d602-792335c543f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\rFetching 98 files:   0% 0/98 [00:00<?, ?it/s]Downloading '.gitattributes' to 'results/transcoder-llama-131k-mntss/.cache/huggingface/download/wPaCkH-WbT7GsmxMKKrNZTV4nSM=.a6344aac8c09253b3b630fb776ae94478aa0275b.incomplete'\n",
            "Downloading 'latents/layers.0.mlp/26214_52427.safetensors' to 'results/transcoder-llama-131k-mntss/.cache/huggingface/download/latents/layers.0.mlp/DfI343hiqeb5QZh_dzGOa9U1tOI=.c5bbbca72561872b97d3bf86ab4eae465d766e8523fadbf242008060b466d863.incomplete'\n",
            "Downloading 'latents/layers.0.mlp/52428_78642.safetensors' to 'results/transcoder-llama-131k-mntss/.cache/huggingface/download/latents/layers.0.mlp/D5ZAGWY4JGprrJuJg32OEAI_coI=.a0ba79d34a60eb29c52e5122315d4fc7549cda57bba493f2e968aaf6f4ad3d8f.incomplete'\n",
            "Downloading 'latents/layers.0.mlp/78643_104856.safetensors' to 'results/transcoder-llama-131k-mntss/.cache/huggingface/download/latents/layers.0.mlp/Z1qsMB7fH8Q67YIj0ULmBJBlW_E=.8c2df0bea2e9e79c262f62d516a84e4cd2a752d8048b99f6b4662f620196396e.incomplete'\n",
            "Downloading 'latents/layers.1.mlp/0_26213.safetensors' to 'results/transcoder-llama-131k-mntss/.cache/huggingface/download/latents/layers.1.mlp/nzlrvqDo6FcYy0VjcCkWRR0e70U=.221f8753bee310bce9f0c5a6917f6264c5eb0ce86b1d8f4c5c0d683e1dc09be4.incomplete'\n",
            "Downloading 'latents/layers.0.mlp/config.json' to 'results/transcoder-llama-131k-mntss/.cache/huggingface/download/latents/layers.0.mlp/8_PA_wEVGiVa2goH2H4KQOQpvVY=.e15d0eb1fb235ccc57b1d72c5aaa2f72eced9fa2.incomplete'\n",
            "Downloading 'latents/layers.0.mlp/104857_131071.safetensors' to 'results/transcoder-llama-131k-mntss/.cache/huggingface/download/latents/layers.0.mlp/lu--7ZbzRrZQs-kWIpm2vw7DCuk=.6f2309f75a68953cff0068a56434c4cee5f083f0d077455ca06241a408f37a2e.incomplete'\n",
            "\n",
            "\rconfig.json:   0% 0.00/279 [00:00<?, ?B/s]\u001b[A\rconfig.json: 100% 279/279 [00:00<00:00, 2.70MB/s]\n",
            "Download complete. Moving file to results/transcoder-llama-131k-mntss/latents/layers.0.mlp/config.json\n",
            "Downloading 'latents/layers.0.mlp/0_26213.safetensors' to 'results/transcoder-llama-131k-mntss/.cache/huggingface/download/latents/layers.0.mlp/nzlrvqDo6FcYy0VjcCkWRR0e70U=.56e350b6d5b35a952529413c6f4c91d16adec385c69b7886f0183fdc6583a1d3.incomplete'\n",
            "\n",
            ".gitattributes: 100% 1.52k/1.52k [00:00<00:00, 16.3MB/s]\n",
            "Download complete. Moving file to results/transcoder-llama-131k-mntss/.gitattributes\n",
            "Fetching 98 files:   1% 1/98 [00:00<00:22,  4.35it/s]\n",
            "0_26213.safetensors:   0% 0.00/107M [00:00<?, ?B/s]\u001b[ADownloading 'latents/layers.1.mlp/26214_52427.safetensors' to 'results/transcoder-llama-131k-mntss/.cache/huggingface/download/latents/layers.1.mlp/DfI343hiqeb5QZh_dzGOa9U1tOI=.d9893fa5fba58f05ce62561a340bbb3d21a35fb96e590113911d97e58c2d5851.incomplete'\n",
            "\n",
            "0_26213.safetensors:  10% 10.5M/107M [00:00<00:01, 59.0MB/s]\u001b[A\n",
            "\n",
            "52428_78642.safetensors:   0% 0.00/106M [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "104857_131071.safetensors:   0% 0.00/109M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "78643_104856.safetensors:   0% 0.00/110M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "26214_52427.safetensors:   0% 0.00/107M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ADownloading 'latents/layers.1.mlp/104857_131071.safetensors' to 'results/transcoder-llama-131k-mntss/.cache/huggingface/download/latents/layers.1.mlp/lu--7ZbzRrZQs-kWIpm2vw7DCuk=.35e55d621fec46ba7525d92b852b8f6f830dfc659ba4ad2c91bf43cfcc185f84.incomplete'\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "26214_52427.safetensors:   0% 0.00/108M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "52428_78642.safetensors:  10% 10.5M/106M [00:00<00:01, 79.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "0_26213.safetensors:   0% 0.00/111M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "0_26213.safetensors:  29% 31.5M/107M [00:00<00:00, 103MB/s] \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "78643_104856.safetensors:  10% 10.5M/110M [00:00<00:01, 72.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "26214_52427.safetensors:  10% 10.5M/107M [00:00<00:01, 67.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "104857_131071.safetensors:  10% 10.5M/109M [00:00<00:01, 54.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "26214_52427.safetensors:  10% 10.5M/108M [00:00<00:01, 75.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "0_26213.safetensors:  49% 52.4M/107M [00:00<00:00, 125MB/s]\u001b[A\n",
            "\n",
            "\n",
            "104857_131071.safetensors:  29% 31.5M/109M [00:00<00:00, 98.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "26214_52427.safetensors:  29% 31.5M/107M [00:00<00:00, 102MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "0_26213.safetensors:   9% 10.5M/111M [00:00<00:02, 44.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "78643_104856.safetensors:  19% 21.0M/110M [00:00<00:01, 57.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "52428_78642.safetensors:  20% 21.0M/106M [00:00<00:01, 50.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "104857_131071.safetensors:   0% 0.00/111M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "0_26213.safetensors: 100% 107M/107M [00:00<00:00, 157MB/s] \n",
            "Download complete. Moving file to results/transcoder-llama-131k-mntss/latents/layers.0.mlp/0_26213.safetensors\n",
            "Fetching 98 files:   2% 2/98 [00:00<00:47,  2.01it/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "26214_52427.safetensors:  39% 41.9M/107M [00:00<00:00, 88.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "78643_104856.safetensors:  29% 31.5M/110M [00:00<00:01, 63.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "104857_131071.safetensors:  38% 41.9M/109M [00:00<00:00, 76.8MB/s]\u001b[A\u001b[A\u001b[ADownloading 'latents/layers.1.mlp/52428_78642.safetensors' to 'results/transcoder-llama-131k-mntss/.cache/huggingface/download/latents/layers.1.mlp/D5ZAGWY4JGprrJuJg32OEAI_coI=.d928f8b03d620695844295e4e0bd8be4d95434ae6a2c3df8b6f8452cb41a895e.incomplete'\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "104857_131071.safetensors:   9% 10.5M/111M [00:00<00:01, 57.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "0_26213.safetensors:  19% 21.0M/111M [00:00<00:01, 46.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "26214_52427.safetensors:  19% 21.0M/108M [00:00<00:02, 33.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "104857_131071.safetensors:  19% 21.0M/111M [00:00<00:01, 61.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "26214_52427.safetensors:  49% 52.4M/107M [00:00<00:00, 62.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "0_26213.safetensors:  28% 31.5M/111M [00:00<00:01, 50.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "52428_78642.safetensors:   0% 0.00/109M [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "\n",
            "104857_131071.safetensors:  48% 52.4M/109M [00:00<00:00, 57.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "78643_104856.safetensors:  38% 41.9M/110M [00:00<00:01, 46.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "26214_52427.safetensors:  29% 31.5M/108M [00:00<00:01, 42.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "52428_78642.safetensors:  30% 31.5M/106M [00:00<00:02, 31.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "104857_131071.safetensors:  28% 31.5M/111M [00:00<00:01, 69.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "52428_78642.safetensors:  10% 10.5M/109M [00:00<00:01, 68.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "26214_52427.safetensors:  69% 73.4M/107M [00:00<00:00, 73.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "104857_131071.safetensors:  38% 41.9M/111M [00:00<00:00, 69.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "26214_52427.safetensors:  39% 41.9M/108M [00:00<00:01, 43.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "52428_78642.safetensors:  39% 41.9M/106M [00:01<00:01, 35.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "0_26213.safetensors:  38% 41.9M/111M [00:00<00:01, 40.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "52428_78642.safetensors:  19% 21.0M/109M [00:00<00:01, 57.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "78643_104856.safetensors:  48% 52.4M/110M [00:01<00:01, 41.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "26214_52427.safetensors:  49% 52.4M/108M [00:01<00:01, 48.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "26214_52427.safetensors:  79% 83.9M/107M [00:01<00:00, 56.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "104857_131071.safetensors:  47% 52.4M/111M [00:00<00:01, 49.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "52428_78642.safetensors:  29% 31.5M/109M [00:00<00:01, 52.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "0_26213.safetensors:  47% 52.4M/111M [00:01<00:01, 41.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "52428_78642.safetensors:  49% 52.4M/106M [00:01<00:01, 37.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "78643_104856.safetensors:  57% 62.9M/110M [00:01<00:01, 42.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "104857_131071.safetensors:  67% 73.4M/109M [00:01<00:00, 42.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "104857_131071.safetensors:  57% 62.9M/111M [00:01<00:00, 58.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "0_26213.safetensors:  57% 62.9M/111M [00:01<00:00, 50.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "52428_78642.safetensors:  39% 41.9M/109M [00:00<00:01, 56.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "78643_104856.safetensors:  67% 73.4M/110M [00:01<00:00, 45.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "26214_52427.safetensors:  68% 73.4M/108M [00:01<00:00, 54.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "26214_52427.safetensors:  98% 105M/107M [00:01<00:00, 58.6MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "26214_52427.safetensors: 100% 107M/107M [00:01<00:00, 65.3MB/s]\n",
            "Download complete. Moving file to results/transcoder-llama-131k-mntss/latents/layers.0.mlp/26214_52427.safetensors\n",
            "\n",
            "\n",
            "52428_78642.safetensors:  69% 73.4M/106M [00:01<00:00, 48.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "78643_104856.safetensors:  77% 83.9M/110M [00:01<00:00, 51.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "52428_78642.safetensors:  48% 52.4M/109M [00:00<00:01, 52.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "26214_52427.safetensors:  87% 94.4M/108M [00:01<00:00, 68.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "0_26213.safetensors:  66% 73.4M/111M [00:01<00:00, 41.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ADownloading 'latents/layers.1.mlp/78643_104856.safetensors' to 'results/transcoder-llama-131k-mntss/.cache/huggingface/download/latents/layers.1.mlp/Z1qsMB7fH8Q67YIj0ULmBJBlW_E=.49e1e233c867b7b73c019049cb928da88d697c4ce25e1884dde556e0a8258d94.incomplete'\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "104857_131071.safetensors:  66% 73.4M/111M [00:01<00:00, 40.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "104857_131071.safetensors:  96% 105M/109M [00:01<00:00, 56.5MB/s] \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "52428_78642.safetensors:  79% 83.9M/106M [00:01<00:00, 45.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "104857_131071.safetensors: 100% 109M/109M [00:01<00:00, 55.6MB/s]\n",
            "Download complete. Moving file to results/transcoder-llama-131k-mntss/latents/layers.0.mlp/104857_131071.safetensors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Fetching 98 files:   3% 3/98 [00:02<01:29,  1.06it/s]Downloading 'latents/layers.1.mlp/config.json' to 'results/transcoder-llama-131k-mntss/.cache/huggingface/download/latents/layers.1.mlp/8_PA_wEVGiVa2goH2H4KQOQpvVY=.e15d0eb1fb235ccc57b1d72c5aaa2f72eced9fa2.incomplete'\n",
            "\n",
            "\n",
            "\n",
            "78643_104856.safetensors:   0% 0.00/113M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "0_26213.safetensors:  76% 83.9M/111M [00:01<00:00, 43.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "config.json: 100% 279/279 [00:00<00:00, 2.26MB/s]\n",
            "Download complete. Moving file to results/transcoder-llama-131k-mntss/latents/layers.1.mlp/config.json\n",
            "26214_52427.safetensors: 100% 108M/108M [00:01<00:00, 55.0MB/s]\n",
            "Download complete. Moving file to results/transcoder-llama-131k-mntss/latents/layers.1.mlp/26214_52427.safetensors\n",
            "Downloading 'latents/layers.10.mlp/0_26213.safetensors' to 'results/transcoder-llama-131k-mntss/.cache/huggingface/download/latents/layers.10.mlp/nzlrvqDo6FcYy0VjcCkWRR0e70U=.4a85161acb075a57480de2eda37b185cd488d2512b5f2e6f901a0addb6911858.incomplete'\n",
            "Downloading 'latents/layers.10.mlp/104857_131071.safetensors' to 'results/transcoder-llama-131k-mntss/.cache/huggingface/download/latents/layers.10.mlp/lu--7ZbzRrZQs-kWIpm2vw7DCuk=.82632ab91e08815a503ba97c3e19bc37f18ff07d67140f75810910faf31af76b.incomplete'\n",
            "78643_104856.safetensors: 100% 110M/110M [00:02<00:00, 51.8MB/s]\n",
            "Download complete. Moving file to results/transcoder-llama-131k-mntss/latents/layers.0.mlp/78643_104856.safetensors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "104857_131071.safetensors:  76% 83.9M/111M [00:01<00:00, 40.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "52428_78642.safetensors:  68% 73.4M/109M [00:01<00:00, 51.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "0_26213.safetensors:  85% 94.4M/111M [00:02<00:00, 50.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ADownloading 'latents/layers.10.mlp/26214_52427.safetensors' to 'results/transcoder-llama-131k-mntss/.cache/huggingface/download/latents/layers.10.mlp/DfI343hiqeb5QZh_dzGOa9U1tOI=.807ee3e54dc671ea4a6d558b2ce3e6b95db0d70fb112b3cce0a816f29781e233.incomplete'\n",
            "\n",
            "\n",
            "52428_78642.safetensors: 100% 106M/106M [00:02<00:00, 47.2MB/s]\n",
            "Download complete. Moving file to results/transcoder-llama-131k-mntss/latents/layers.0.mlp/52428_78642.safetensors\n",
            "Fetching 98 files:   5% 5/98 [00:02<00:45,  2.04it/s]Downloading 'latents/layers.10.mlp/52428_78642.safetensors' to 'results/transcoder-llama-131k-mntss/.cache/huggingface/download/latents/layers.10.mlp/D5ZAGWY4JGprrJuJg32OEAI_coI=.a7bf09049c805443e7f8524186954edde69c4d9d6d8160b8ac65d92711ef1466.incomplete'\n",
            "\n",
            "\n",
            "\n",
            "78643_104856.safetensors:  19% 21.0M/113M [00:00<00:01, 76.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "104857_131071.safetensors:   0% 0.00/109M [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "104857_131071.safetensors:  85% 94.4M/111M [00:01<00:00, 42.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "52428_78642.safetensors:  77% 83.9M/109M [00:01<00:00, 47.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "0_26213.safetensors:   0% 0.00/109M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "78643_104856.safetensors:  28% 31.5M/113M [00:00<00:01, 76.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "26214_52427.safetensors:   0% 0.00/105M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "104857_131071.safetensors:  10% 10.5M/109M [00:00<00:01, 71.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "0_26213.safetensors:  95% 105M/111M [00:02<00:00, 40.0MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "26214_52427.safetensors:  10% 10.5M/105M [00:00<00:01, 89.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "52428_78642.safetensors:   0% 0.00/107M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "0_26213.safetensors:  10% 10.5M/109M [00:00<00:01, 57.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "104857_131071.safetensors:  94% 105M/111M [00:02<00:00, 39.6MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "104857_131071.safetensors:  29% 31.5M/109M [00:00<00:00, 96.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "78643_104856.safetensors:  37% 41.9M/113M [00:00<00:01, 59.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "52428_78642.safetensors:  97% 105M/109M [00:01<00:00, 56.4MB/s] \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "52428_78642.safetensors: 100% 109M/109M [00:01<00:00, 55.5MB/s]\n",
            "Download complete. Moving file to results/transcoder-llama-131k-mntss/latents/layers.1.mlp/52428_78642.safetensors\n",
            "0_26213.safetensors: 100% 111M/111M [00:02<00:00, 42.6MB/s]\n",
            "Download complete. Moving file to results/transcoder-llama-131k-mntss/latents/layers.1.mlp/0_26213.safetensors\n",
            "Fetching 98 files:   8% 8/98 [00:03<00:27,  3.22it/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "104857_131071.safetensors: 100% 111M/111M [00:02<00:00, 46.8MB/s]\n",
            "Download complete. Moving file to results/transcoder-llama-131k-mntss/latents/layers.1.mlp/104857_131071.safetensors\n",
            "Downloading 'latents/layers.10.mlp/78643_104856.safetensors' to 'results/transcoder-llama-131k-mntss/.cache/huggingface/download/latents/layers.10.mlp/Z1qsMB7fH8Q67YIj0ULmBJBlW_E=.a5aa210d214a55cb3ed996be637bc6276f2513625a618baf05f4f60f397400c5.incomplete'\n",
            "Downloading 'latents/layers.10.mlp/config.json' to 'results/transcoder-llama-131k-mntss/.cache/huggingface/download/latents/layers.10.mlp/8_PA_wEVGiVa2goH2H4KQOQpvVY=.e15d0eb1fb235ccc57b1d72c5aaa2f72eced9fa2.incomplete'\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "26214_52427.safetensors:  20% 21.0M/105M [00:00<00:01, 54.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ADownloading 'latents/layers.11.mlp/0_26213.safetensors' to 'results/transcoder-llama-131k-mntss/.cache/huggingface/download/latents/layers.11.mlp/nzlrvqDo6FcYy0VjcCkWRR0e70U=.691412dfd6f2292d95a912ed27d9e9a5a30ac98e3c02213919e87b7f7424b806.incomplete'\n",
            "\n",
            "config.json: 100% 279/279 [00:00<00:00, 3.31MB/s]\n",
            "Download complete. Moving file to results/transcoder-llama-131k-mntss/latents/layers.10.mlp/config.json\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "0_26213.safetensors:  19% 21.0M/109M [00:00<00:01, 47.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "52428_78642.safetensors:  20% 21.0M/107M [00:00<00:01, 75.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ADownloading 'latents/layers.11.mlp/104857_131071.safetensors' to 'results/transcoder-llama-131k-mntss/.cache/huggingface/download/latents/layers.11.mlp/lu--7ZbzRrZQs-kWIpm2vw7DCuk=.403257c9860b2cfaf4e0899bb129166872c9bbafd8749a04c6d7a42f34047db7.incomplete'\n",
            "\n",
            "\n",
            "\n",
            "78643_104856.safetensors:  47% 52.4M/113M [00:00<00:01, 51.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "26214_52427.safetensors:  30% 31.5M/105M [00:00<00:01, 59.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "78643_104856.safetensors:   0% 0.00/111M [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "104857_131071.safetensors:  39% 41.9M/109M [00:00<00:01, 49.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "78643_104856.safetensors:  56% 62.9M/113M [00:01<00:00, 56.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "0_26213.safetensors:  29% 31.5M/109M [00:00<00:01, 45.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "0_26213.safetensors:   0% 0.00/109M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "52428_78642.safetensors:  39% 41.9M/107M [00:00<00:00, 73.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "78643_104856.safetensors:   9% 10.5M/111M [00:00<00:01, 60.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "104857_131071.safetensors:   0% 0.00/109M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "26214_52427.safetensors:  40% 41.9M/105M [00:00<00:01, 49.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "104857_131071.safetensors:  48% 52.4M/109M [00:00<00:01, 54.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "0_26213.safetensors:  39% 41.9M/109M [00:00<00:01, 51.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "0_26213.safetensors:  10% 10.5M/109M [00:00<00:01, 57.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "78643_104856.safetensors:  19% 21.0M/111M [00:00<00:01, 67.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "26214_52427.safetensors:  50% 52.4M/105M [00:00<00:00, 60.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "78643_104856.safetensors:  65% 73.4M/113M [00:01<00:00, 48.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "52428_78642.safetensors:  49% 52.4M/107M [00:00<00:00, 55.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "0_26213.safetensors:  48% 52.4M/109M [00:01<00:01, 50.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "0_26213.safetensors:  29% 31.5M/109M [00:00<00:00, 86.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "78643_104856.safetensors:  28% 31.5M/111M [00:00<00:01, 58.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "78643_104856.safetensors:  74% 83.9M/113M [00:01<00:00, 49.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "26214_52427.safetensors:  70% 73.4M/105M [00:01<00:00, 67.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "52428_78642.safetensors:  59% 62.9M/107M [00:01<00:00, 54.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "104857_131071.safetensors:  10% 10.5M/109M [00:00<00:04, 23.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "0_26213.safetensors:  38% 41.9M/109M [00:00<00:00, 71.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "104857_131071.safetensors:  67% 73.4M/109M [00:01<00:00, 49.5MB/s]\u001b[A\u001b[A\n",
            "78643_104856.safetensors:  38% 41.9M/111M [00:00<00:01, 52.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "52428_78642.safetensors:  68% 73.4M/107M [00:01<00:00, 58.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "0_26213.safetensors:  67% 73.4M/109M [00:01<00:00, 54.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "78643_104856.safetensors:  93% 105M/113M [00:01<00:00, 59.7MB/s] \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "104857_131071.safetensors:  19% 21.0M/109M [00:00<00:02, 35.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "26214_52427.safetensors:  80% 83.9M/105M [00:01<00:00, 55.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "0_26213.safetensors:  48% 52.4M/109M [00:00<00:00, 57.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "78643_104856.safetensors:  47% 52.4M/111M [00:00<00:01, 54.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "104857_131071.safetensors:  29% 31.5M/109M [00:00<00:01, 48.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "0_26213.safetensors:  77% 83.9M/109M [00:01<00:00, 51.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "104857_131071.safetensors:  77% 83.9M/109M [00:01<00:00, 41.0MB/s]\u001b[A\u001b[A\n",
            "78643_104856.safetensors:  57% 62.9M/111M [00:01<00:00, 58.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "0_26213.safetensors:  57% 62.9M/109M [00:00<00:00, 60.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "104857_131071.safetensors:  39% 41.9M/109M [00:00<00:01, 56.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "52428_78642.safetensors:  78% 83.9M/107M [00:01<00:00, 46.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "78643_104856.safetensors: 100% 113M/113M [00:02<00:00, 51.0MB/s]\n",
            "Download complete. Moving file to results/transcoder-llama-131k-mntss/latents/layers.1.mlp/78643_104856.safetensors\n",
            "Fetching 98 files:  12% 12/98 [00:04<00:29,  2.90it/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "104857_131071.safetensors:  48% 52.4M/109M [00:01<00:00, 60.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ADownloading 'latents/layers.11.mlp/26214_52427.safetensors' to 'results/transcoder-llama-131k-mntss/.cache/huggingface/download/latents/layers.11.mlp/DfI343hiqeb5QZh_dzGOa9U1tOI=.04121c34b2d2e976cbf9bccfb12609724233499f108b6f3575dbdf1b1fb974f0.incomplete'\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "26214_52427.safetensors: 100% 105M/105M [00:01<00:00, 56.5MB/s]\n",
            "Download complete. Moving file to results/transcoder-llama-131k-mntss/latents/layers.10.mlp/26214_52427.safetensors\n",
            "\n",
            "78643_104856.safetensors:  66% 73.4M/111M [00:01<00:00, 52.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "0_26213.safetensors:  67% 73.4M/109M [00:01<00:00, 51.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ADownloading 'latents/layers.11.mlp/52428_78642.safetensors' to 'results/transcoder-llama-131k-mntss/.cache/huggingface/download/latents/layers.11.mlp/D5ZAGWY4JGprrJuJg32OEAI_coI=.0cd3b5ae3c8f94541288133c2d968a7d9dd5316edc4885427b32a131bfdd6c51.incomplete'\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "0_26213.safetensors:  87% 94.4M/109M [00:01<00:00, 43.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "104857_131071.safetensors:  58% 62.9M/109M [00:01<00:00, 65.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "78643_104856.safetensors:  76% 83.9M/111M [00:01<00:00, 57.4MB/s]\u001b[A\n",
            "\n",
            "104857_131071.safetensors:  96% 105M/109M [00:02<00:00, 44.6MB/s] \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "52428_78642.safetensors: 100% 107M/107M [00:01<00:00, 54.0MB/s]\n",
            "Download complete. Moving file to results/transcoder-llama-131k-mntss/latents/layers.10.mlp/52428_78642.safetensors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "104857_131071.safetensors: 100% 109M/109M [00:02<00:00, 48.2MB/s]\n",
            "Download complete. Moving file to results/transcoder-llama-131k-mntss/latents/layers.10.mlp/104857_131071.safetensors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "0_26213.safetensors:  96% 105M/109M [00:02<00:00, 45.2MB/s] \u001b[A\u001b[A\u001b[A\u001b[ADownloading 'latents/layers.11.mlp/78643_104856.safetensors' to 'results/transcoder-llama-131k-mntss/.cache/huggingface/download/latents/layers.11.mlp/Z1qsMB7fH8Q67YIj0ULmBJBlW_E=.99e2c71bd43171ff1cdd6c8817e4aae374454d4e4a12063145a87ef981f404a6.incomplete'\n",
            "\n",
            "\n",
            "52428_78642.safetensors:   0% 0.00/108M [00:00<?, ?B/s]\u001b[A\u001b[ADownloading 'latents/layers.11.mlp/config.json' to 'results/transcoder-llama-131k-mntss/.cache/huggingface/download/latents/layers.11.mlp/8_PA_wEVGiVa2goH2H4KQOQpvVY=.e15d0eb1fb235ccc57b1d72c5aaa2f72eced9fa2.incomplete'\n",
            "\n",
            "\n",
            "\n",
            "26214_52427.safetensors:   0% 0.00/112M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "config.json: 100% 279/279 [00:00<00:00, 2.77MB/s]\n",
            "Download complete. Moving file to results/transcoder-llama-131k-mntss/latents/layers.11.mlp/config.json\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "104857_131071.safetensors:  68% 73.4M/109M [00:01<00:00, 48.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "52428_78642.safetensors:  10% 10.5M/108M [00:00<00:01, 92.7MB/s]\u001b[A\u001b[ADownloading 'latents/layers.12.mlp/0_26213.safetensors' to 'results/transcoder-llama-131k-mntss/.cache/huggingface/download/latents/layers.12.mlp/nzlrvqDo6FcYy0VjcCkWRR0e70U=.c6a171abaec5cfe84683925e24595df65578e4249b3d837c282e4569459c9600.incomplete'\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "0_26213.safetensors: 100% 109M/109M [00:02<00:00, 46.6MB/s]\n",
            "Download complete. Moving file to results/transcoder-llama-131k-mntss/latents/layers.10.mlp/0_26213.safetensors\n",
            "Fetching 98 files:  14% 14/98 [00:05<00:27,  3.11it/s]\n",
            "\n",
            "\n",
            "26214_52427.safetensors:   9% 10.5M/112M [00:00<00:01, 83.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "78643_104856.safetensors:  95% 105M/111M [00:01<00:00, 61.0MB/s] \u001b[ADownloading 'latents/layers.12.mlp/104857_131071.safetensors' to 'results/transcoder-llama-131k-mntss/.cache/huggingface/download/latents/layers.12.mlp/lu--7ZbzRrZQs-kWIpm2vw7DCuk=.840a30760acfd7ffe7a9a9ad9aeb42988094c029b26b28e66558d9f3d575c2d8.incomplete'\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "78643_104856.safetensors: 100% 111M/111M [00:01<00:00, 58.4MB/s]\n",
            "Download complete. Moving file to results/transcoder-llama-131k-mntss/latents/layers.10.mlp/78643_104856.safetensors\n",
            "Fetching 98 files:  18% 18/98 [00:05<00:15,  5.08it/s]\n",
            "\n",
            "52428_78642.safetensors:  19% 21.0M/108M [00:00<00:01, 59.0MB/s]\u001b[A\u001b[ADownloading 'latents/layers.12.mlp/26214_52427.safetensors' to 'results/transcoder-llama-131k-mntss/.cache/huggingface/download/latents/layers.12.mlp/DfI343hiqeb5QZh_dzGOa9U1tOI=.02b3b115160769b434966613265b751487fce7bb71d89049fed98634094244bd.incomplete'\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "0_26213.safetensors:  96% 105M/109M [00:01<00:00, 51.4MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "26214_52427.safetensors:  19% 21.0M/112M [00:00<00:01, 55.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "0_26213.safetensors: 100% 109M/109M [00:01<00:00, 55.7MB/s]\n",
            "Download complete. Moving file to results/transcoder-llama-131k-mntss/latents/layers.11.mlp/0_26213.safetensors\n",
            "Fetching 98 files:  20% 20/98 [00:05<00:13,  5.87it/s]\n",
            "\n",
            "52428_78642.safetensors:  29% 31.5M/108M [00:00<00:01, 70.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "104857_131071.safetensors:   0% 0.00/112M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "104857_131071.safetensors:  77% 83.9M/109M [00:01<00:00, 40.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "78643_104856.safetensors:   9% 10.5M/111M [00:00<00:02, 37.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "26214_52427.safetensors:  28% 31.5M/112M [00:00<00:01, 66.0MB/s]\u001b[A\u001b[A\u001b[ADownloading 'latents/layers.12.mlp/52428_78642.safetensors' to 'results/transcoder-llama-131k-mntss/.cache/huggingface/download/latents/layers.12.mlp/D5ZAGWY4JGprrJuJg32OEAI_coI=.cdb11c06810538aaf4a0448d868b1d2dda55f59383f1d1477ab967652427375b.incomplete'\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "104857_131071.safetensors:  87% 94.4M/109M [00:01<00:00, 48.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "78643_104856.safetensors:  19% 21.0M/111M [00:00<00:01, 56.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "26214_52427.safetensors:   0% 0.00/110M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "104857_131071.safetensors:   9% 10.5M/112M [00:00<00:01, 53.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "26214_52427.safetensors:  37% 41.9M/112M [00:00<00:01, 67.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "52428_78642.safetensors:  39% 41.9M/108M [00:00<00:01, 58.6MB/s]\u001b[A\u001b[A\n",
            "0_26213.safetensors:  18% 21.0M/113M [00:00<00:01, 61.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "26214_52427.safetensors:  47% 52.4M/112M [00:00<00:00, 69.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "26214_52427.safetensors:  10% 10.5M/110M [00:00<00:01, 53.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "52428_78642.safetensors:   0% 0.00/106M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "104857_131071.safetensors:  28% 31.5M/112M [00:00<00:00, 81.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "78643_104856.safetensors:  38% 41.9M/111M [00:00<00:01, 67.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "104857_131071.safetensors:  96% 105M/109M [00:02<00:00, 40.3MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "26214_52427.safetensors:  56% 62.9M/112M [00:00<00:00, 69.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "104857_131071.safetensors:  38% 41.9M/112M [00:00<00:00, 87.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "104857_131071.safetensors: 100% 109M/109M [00:02<00:00, 45.1MB/s]\n",
            "Download complete. Moving file to results/transcoder-llama-131k-mntss/latents/layers.11.mlp/104857_131071.safetensors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "52428_78642.safetensors:  10% 10.5M/106M [00:00<00:01, 50.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "52428_78642.safetensors:  49% 52.4M/108M [00:01<00:01, 42.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "26214_52427.safetensors:  19% 21.0M/110M [00:00<00:01, 47.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "78643_104856.safetensors:  47% 52.4M/111M [00:00<00:00, 61.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "26214_52427.safetensors:  66% 73.4M/112M [00:01<00:00, 70.7MB/s]\u001b[A\u001b[A\u001b[ADownloading 'latents/layers.12.mlp/78643_104856.safetensors' to 'results/transcoder-llama-131k-mntss/.cache/huggingface/download/latents/layers.12.mlp/Z1qsMB7fH8Q67YIj0ULmBJBlW_E=.1b8f589e76ff9c8a1c41875816b958539077ea6c5d61b7246d6b428a4a03b8b7.incomplete'\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "104857_131071.safetensors:  47% 52.4M/112M [00:00<00:00, 74.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "0_26213.safetensors:  37% 41.9M/113M [00:00<00:01, 51.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "26214_52427.safetensors:  29% 31.5M/110M [00:00<00:01, 56.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "26214_52427.safetensors:  75% 83.9M/112M [00:01<00:00, 60.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "52428_78642.safetensors:  30% 31.5M/106M [00:00<00:01, 64.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "52428_78642.safetensors:  68% 73.4M/108M [00:01<00:00, 52.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "78643_104856.safetensors:  66% 73.4M/111M [00:01<00:00, 62.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "26214_52427.safetensors:  84% 94.4M/112M [00:01<00:00, 65.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "78643_104856.safetensors:   0% 0.00/111M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "0_26213.safetensors:  46% 52.4M/113M [00:01<00:01, 46.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "104857_131071.safetensors:  66% 73.4M/112M [00:01<00:00, 67.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "52428_78642.safetensors:  40% 41.9M/106M [00:00<00:01, 59.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "26214_52427.safetensors:  38% 41.9M/110M [00:00<00:01, 41.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "78643_104856.safetensors:  75% 83.9M/111M [00:01<00:00, 57.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "0_26213.safetensors:  65% 73.4M/113M [00:01<00:00, 64.4MB/s]\u001b[A\n",
            "\n",
            "52428_78642.safetensors:  78% 83.9M/108M [00:01<00:00, 43.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "26214_52427.safetensors:  94% 105M/112M [00:01<00:00, 51.2MB/s] \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "52428_78642.safetensors:  50% 52.4M/106M [00:00<00:01, 52.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "26214_52427.safetensors: 100% 112M/112M [00:01<00:00, 61.1MB/s]\n",
            "Download complete. Moving file to results/transcoder-llama-131k-mntss/latents/layers.11.mlp/26214_52427.safetensors\n",
            "Fetching 98 files:  22% 22/98 [00:06<00:23,  3.26it/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "26214_52427.safetensors:  48% 52.4M/110M [00:01<00:01, 38.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "104857_131071.safetensors:  75% 83.9M/112M [00:01<00:00, 48.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "0_26213.safetensors:  74% 83.9M/113M [00:01<00:00, 57.7MB/s]\u001b[ADownloading 'latents/layers.12.mlp/config.json' to 'results/transcoder-llama-131k-mntss/.cache/huggingface/download/latents/layers.12.mlp/8_PA_wEVGiVa2goH2H4KQOQpvVY=.e15d0eb1fb235ccc57b1d72c5aaa2f72eced9fa2.incomplete'\n",
            "\n",
            "\n",
            "\n",
            "config.json: 100% 279/279 [00:00<00:00, 2.87MB/s]\n",
            "Download complete. Moving file to results/transcoder-llama-131k-mntss/latents/layers.12.mlp/config.json\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "78643_104856.safetensors:  19% 21.0M/111M [00:00<00:02, 42.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "52428_78642.safetensors:  70% 73.4M/106M [00:01<00:00, 68.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ADownloading 'latents/layers.13.mlp/0_26213.safetensors' to 'results/transcoder-llama-131k-mntss/.cache/huggingface/download/latents/layers.13.mlp/nzlrvqDo6FcYy0VjcCkWRR0e70U=.5f25bfe4fc2ffbccdaecad2287d1857450473130e64e96fd7002639da3e01e72.incomplete'\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "78643_104856.safetensors: 100% 111M/111M [00:01<00:00, 59.0MB/s]\n",
            "Download complete. Moving file to results/transcoder-llama-131k-mntss/latents/layers.11.mlp/78643_104856.safetensors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "78643_104856.safetensors:  28% 31.5M/111M [00:00<00:01, 55.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "0_26213.safetensors:  92% 105M/113M [00:01<00:00, 68.7MB/s] \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "104857_131071.safetensors:  94% 105M/112M [00:01<00:00, 59.2MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[ADownloading 'latents/layers.13.mlp/104857_131071.safetensors' to 'results/transcoder-llama-131k-mntss/.cache/huggingface/download/latents/layers.13.mlp/lu--7ZbzRrZQs-kWIpm2vw7DCuk=.791e3c8beee6e7728f8e34af8f6ba0c835751ceb2c78726c7b6bc5b3ab467e0e.incomplete'\n",
            "104857_131071.safetensors: 100% 112M/112M [00:01<00:00, 65.2MB/s]\n",
            "Download complete. Moving file to results/transcoder-llama-131k-mntss/latents/layers.12.mlp/104857_131071.safetensors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "78643_104856.safetensors:  38% 41.9M/111M [00:00<00:01, 66.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ADownloading 'latents/layers.13.mlp/26214_52427.safetensors' to 'results/transcoder-llama-131k-mntss/.cache/huggingface/download/latents/layers.13.mlp/DfI343hiqeb5QZh_dzGOa9U1tOI=.206f2383604780a04552141c13b0fa9847e43d1ed87b0829c167d126eaf6f014.incomplete'\n",
            "\n",
            "0_26213.safetensors: 100% 113M/113M [00:01<00:00, 61.8MB/s]\n",
            "Download complete. Moving file to results/transcoder-llama-131k-mntss/latents/layers.12.mlp/0_26213.safetensors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "26214_52427.safetensors:  67% 73.4M/110M [00:01<00:00, 44.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "52428_78642.safetensors:  79% 83.9M/106M [00:01<00:00, 55.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ADownloading 'latents/layers.13.mlp/52428_78642.safetensors' to 'results/transcoder-llama-131k-mntss/.cache/huggingface/download/latents/layers.13.mlp/D5ZAGWY4JGprrJuJg32OEAI_coI=.994e20c8ef7b5c7156e174d47b5bc62af876ada5d0019b7f468fa22b47648cc7.incomplete'\n",
            "\n",
            "104857_131071.safetensors:   0% 0.00/113M [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "\n",
            "0_26213.safetensors:   0% 0.00/109M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "78643_104856.safetensors:  56% 62.9M/111M [00:00<00:00, 81.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "104857_131071.safetensors:   9% 10.5M/113M [00:00<00:01, 86.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "0_26213.safetensors:  10% 10.5M/109M [00:00<00:01, 66.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "26214_52427.safetensors:   0% 0.00/111M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "52428_78642.safetensors:   0% 0.00/109M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "26214_52427.safetensors:  77% 83.9M/110M [00:01<00:00, 40.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "52428_78642.safetensors: 100% 106M/106M [00:01<00:00, 59.4MB/s]\n",
            "Download complete. Moving file to results/transcoder-llama-131k-mntss/latents/layers.12.mlp/52428_78642.safetensors\n",
            "\n",
            "104857_131071.safetensors:  19% 21.0M/113M [00:00<00:01, 61.4MB/s]\u001b[ADownloading 'latents/layers.13.mlp/78643_104856.safetensors' to 'results/transcoder-llama-131k-mntss/.cache/huggingface/download/latents/layers.13.mlp/Z1qsMB7fH8Q67YIj0ULmBJBlW_E=.87d95b92212690aabb2b3f4215fb4ab1251b15f50558de95ac898739d4782e12.incomplete'\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "26214_52427.safetensors:   9% 10.5M/111M [00:00<00:01, 62.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "52428_78642.safetensors:  10% 10.5M/109M [00:00<00:01, 54.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "104857_131071.safetensors:  28% 31.5M/113M [00:00<00:01, 73.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "78643_104856.safetensors:  66% 73.4M/111M [00:01<00:00, 52.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "26214_52427.safetensors:  96% 105M/110M [00:02<00:00, 53.7MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "0_26213.safetensors:  19% 21.0M/109M [00:00<00:02, 43.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "52428_78642.safetensors:  97% 105M/108M [00:02<00:00, 27.5MB/s] \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "52428_78642.safetensors: 100% 108M/108M [00:02<00:00, 37.4MB/s]\n",
            "Download complete. Moving file to results/transcoder-llama-131k-mntss/latents/layers.11.mlp/52428_78642.safetensors\n",
            "Fetching 98 files:  23% 23/98 [00:07<00:31,  2.41it/s]\n",
            "\n",
            "78643_104856.safetensors:   0% 0.00/108M [00:00<?, ?B/s]\u001b[A\u001b[ADownloading 'latents/layers.13.mlp/config.json' to 'results/transcoder-llama-131k-mntss/.cache/huggingface/download/latents/layers.13.mlp/8_PA_wEVGiVa2goH2H4KQOQpvVY=.e15d0eb1fb235ccc57b1d72c5aaa2f72eced9fa2.incomplete'\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "52428_78642.safetensors:  19% 21.0M/109M [00:00<00:01, 45.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "0_26213.safetensors:  38% 41.9M/109M [00:00<00:00, 67.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "26214_52427.safetensors: 100% 110M/110M [00:02<00:00, 45.2MB/s]\n",
            "Download complete. Moving file to results/transcoder-llama-131k-mntss/latents/layers.12.mlp/26214_52427.safetensors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Fetching 98 files:  29% 28/98 [00:08<00:15,  4.61it/s]\n",
            "104857_131071.safetensors:  37% 41.9M/113M [00:00<00:01, 52.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "26214_52427.safetensors:  28% 31.5M/111M [00:00<00:01, 54.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "config.json: 100% 279/279 [00:00<00:00, 2.87MB/s]\n",
            "Download complete. Moving file to results/transcoder-llama-131k-mntss/latents/layers.13.mlp/config.json\n",
            "Downloading 'latents/layers.14.mlp/0_26213.safetensors' to 'results/transcoder-llama-131k-mntss/.cache/huggingface/download/latents/layers.14.mlp/nzlrvqDo6FcYy0VjcCkWRR0e70U=.c7ec55459c552fd2e1a560dddfa79da3011134a55f6db231891773e3cdd5c455.incomplete'\n",
            "Downloading 'latents/layers.14.mlp/104857_131071.safetensors' to 'results/transcoder-llama-131k-mntss/.cache/huggingface/download/latents/layers.14.mlp/lu--7ZbzRrZQs-kWIpm2vw7DCuk=.5e1cda53fcd60b0e19b7db820aa4e3753d9a31871da13877ffa500475bd1dc5a.incomplete'\n",
            "\n",
            "104857_131071.safetensors:  46% 52.4M/113M [00:00<00:01, 57.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "52428_78642.safetensors:  29% 31.5M/109M [00:00<00:01, 45.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "78643_104856.safetensors:  85% 94.4M/111M [00:01<00:00, 47.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "26214_52427.safetensors:  38% 41.9M/111M [00:00<00:01, 51.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "0_26213.safetensors:   0% 0.00/110M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "104857_131071.safetensors:  56% 62.9M/113M [00:00<00:00, 65.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "104857_131071.safetensors:   0% 0.00/110M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "78643_104856.safetensors:  19% 21.0M/108M [00:00<00:02, 42.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "0_26213.safetensors:  48% 52.4M/109M [00:01<00:01, 46.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "0_26213.safetensors:  10% 10.5M/110M [00:00<00:01, 67.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "78643_104856.safetensors:  94% 105M/111M [00:02<00:00, 48.5MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "78643_104856.safetensors:  29% 31.5M/108M [00:00<00:01, 55.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "52428_78642.safetensors:  38% 41.9M/109M [00:01<00:01, 37.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "78643_104856.safetensors:  39% 41.9M/108M [00:00<00:01, 59.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "0_26213.safetensors:  19% 21.0M/110M [00:00<00:01, 57.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "0_26213.safetensors:  67% 73.4M/109M [00:01<00:00, 55.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "26214_52427.safetensors:  47% 52.4M/111M [00:01<00:01, 37.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "104857_131071.safetensors:  65% 73.4M/113M [00:01<00:00, 44.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "52428_78642.safetensors:  58% 62.9M/109M [00:01<00:00, 60.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "0_26213.safetensors:  29% 31.5M/110M [00:00<00:01, 65.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "26214_52427.safetensors:  56% 62.9M/111M [00:01<00:01, 46.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "78643_104856.safetensors:  48% 52.4M/108M [00:00<00:00, 56.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "78643_104856.safetensors: 100% 111M/111M [00:02<00:00, 45.6MB/s]\n",
            "Download complete. Moving file to results/transcoder-llama-131k-mntss/latents/layers.12.mlp/78643_104856.safetensors\n",
            "Fetching 98 files:  31% 30/98 [00:08<00:17,  3.78it/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "104857_131071.safetensors:   9% 10.5M/110M [00:00<00:05, 18.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "0_26213.safetensors:  38% 41.9M/110M [00:00<00:00, 73.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "104857_131071.safetensors:  83% 94.4M/113M [00:01<00:00, 60.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "0_26213.safetensors:  77% 83.9M/109M [00:01<00:00, 50.4MB/s]\u001b[A\u001b[A\u001b[ADownloading 'latents/layers.14.mlp/26214_52427.safetensors' to 'results/transcoder-llama-131k-mntss/.cache/huggingface/download/latents/layers.14.mlp/DfI343hiqeb5QZh_dzGOa9U1tOI=.20f1aa0125ba961b41da465eaf6141bc44cb958259dedd353d822c1f3bd59279.incomplete'\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "52428_78642.safetensors:  67% 73.4M/109M [00:01<00:00, 56.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "104857_131071.safetensors:  28% 31.5M/110M [00:00<00:01, 54.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "26214_52427.safetensors:  66% 73.4M/111M [00:01<00:00, 45.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "78643_104856.safetensors:  68% 73.4M/108M [00:01<00:00, 62.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "52428_78642.safetensors:  77% 83.9M/109M [00:01<00:00, 54.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "26214_52427.safetensors:  75% 83.9M/111M [00:01<00:00, 52.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "0_26213.safetensors:  48% 52.4M/110M [00:00<00:01, 52.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "26214_52427.safetensors:   0% 0.00/110M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "26214_52427.safetensors:  85% 94.4M/111M [00:01<00:00, 57.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "104857_131071.safetensors:  47% 52.4M/110M [00:01<00:01, 57.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "0_26213.safetensors:  96% 105M/109M [00:02<00:00, 49.7MB/s] \u001b[A\u001b[A\u001b[A\n",
            "104857_131071.safetensors:  93% 105M/113M [00:02<00:00, 42.7MB/s] \u001b[A\n",
            "\n",
            "78643_104856.safetensors:  77% 83.9M/108M [00:01<00:00, 54.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "52428_78642.safetensors:  86% 94.4M/109M [00:01<00:00, 46.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "104857_131071.safetensors: 100% 113M/113M [00:02<00:00, 51.6MB/s]\n",
            "Download complete. Moving file to results/transcoder-llama-131k-mntss/latents/layers.13.mlp/104857_131071.safetensors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "0_26213.safetensors:  67% 73.4M/110M [00:01<00:00, 55.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ADownloading 'latents/layers.14.mlp/52428_78642.safetensors' to 'results/transcoder-llama-131k-mntss/.cache/huggingface/download/latents/layers.14.mlp/D5ZAGWY4JGprrJuJg32OEAI_coI=.6492dfbfb4556df153bdcb51d842be618006b6f75a0e87633d3639a65f2785f1.incomplete'\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "26214_52427.safetensors:  94% 105M/111M [00:02<00:00, 51.0MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "0_26213.safetensors: 100% 109M/109M [00:02<00:00, 48.5MB/s]\n",
            "Download complete. Moving file to results/transcoder-llama-131k-mntss/latents/layers.13.mlp/0_26213.safetensors\n",
            "Fetching 98 files:  33% 32/98 [00:09<00:18,  3.48it/s]Downloading 'latents/layers.14.mlp/78643_104856.safetensors' to 'results/transcoder-llama-131k-mntss/.cache/huggingface/download/latents/layers.14.mlp/Z1qsMB7fH8Q67YIj0ULmBJBlW_E=.9cbf762318d8ec012e292bedcd066d57afd4c683916c1434fba0eae61c4cbb62.incomplete'\n",
            "26214_52427.safetensors: 100% 111M/111M [00:02<00:00, 51.3MB/s]\n",
            "Download complete. Moving file to results/transcoder-llama-131k-mntss/latents/layers.13.mlp/26214_52427.safetensors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "52428_78642.safetensors:  96% 105M/109M [00:02<00:00, 47.4MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[ADownloading 'latents/layers.14.mlp/config.json' to 'results/transcoder-llama-131k-mntss/.cache/huggingface/download/latents/layers.14.mlp/8_PA_wEVGiVa2goH2H4KQOQpvVY=.e15d0eb1fb235ccc57b1d72c5aaa2f72eced9fa2.incomplete'\n",
            "\n",
            "config.json: 100% 279/279 [00:00<00:00, 2.15MB/s]\n",
            "Download complete. Moving file to results/transcoder-llama-131k-mntss/latents/layers.14.mlp/config.json\n",
            "\n",
            "52428_78642.safetensors:   0% 0.00/108M [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "26214_52427.safetensors:  10% 10.5M/110M [00:00<00:04, 20.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "104857_131071.safetensors:  66% 73.4M/110M [00:01<00:00, 51.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ADownloading 'latents/layers.15.mlp/0_26213.safetensors' to 'results/transcoder-llama-131k-mntss/.cache/huggingface/download/latents/layers.15.mlp/nzlrvqDo6FcYy0VjcCkWRR0e70U=.1e7f36353cfed3f360bb643577ce9e9271350b764b96292bce6d970fc79360e0.incomplete'\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "0_26213.safetensors:  76% 83.9M/110M [00:01<00:00, 50.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "52428_78642.safetensors: 100% 109M/109M [00:02<00:00, 47.4MB/s]\n",
            "Download complete. Moving file to results/transcoder-llama-131k-mntss/latents/layers.13.mlp/52428_78642.safetensors\n",
            "Fetching 98 files:  36% 35/98 [00:09<00:13,  4.61it/s]Downloading 'latents/layers.15.mlp/104857_131071.safetensors' to 'results/transcoder-llama-131k-mntss/.cache/huggingface/download/latents/layers.15.mlp/lu--7ZbzRrZQs-kWIpm2vw7DCuk=.3755221bb8c87a46eb7fd293451909e34f6c8055fc942c4dee2916de8b57d8a5.incomplete'\n",
            "\n",
            "\n",
            "\n",
            "78643_104856.safetensors: 100% 108M/108M [00:02<00:00, 52.5MB/s]\n",
            "Download complete. Moving file to results/transcoder-llama-131k-mntss/latents/layers.13.mlp/78643_104856.safetensors\n",
            "Fetching 98 files:  37% 36/98 [00:10<00:12,  4.92it/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "26214_52427.safetensors:  19% 21.0M/110M [00:00<00:02, 30.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "104857_131071.safetensors:  76% 83.9M/110M [00:01<00:00, 52.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ADownloading 'latents/layers.15.mlp/26214_52427.safetensors' to 'results/transcoder-llama-131k-mntss/.cache/huggingface/download/latents/layers.15.mlp/DfI343hiqeb5QZh_dzGOa9U1tOI=.7348126ab3747610fe5da829fdf76f3e200f0aa7fd8adee9de98b204195cf471.incomplete'\n",
            "\n",
            "\n",
            "0_26213.safetensors:   0% 0.00/55.1M [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "52428_78642.safetensors:  10% 10.5M/108M [00:00<00:02, 37.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "104857_131071.safetensors:   0% 0.00/60.5M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "52428_78642.safetensors:  19% 21.0M/108M [00:00<00:01, 57.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "26214_52427.safetensors:  29% 31.5M/110M [00:00<00:01, 39.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "104857_131071.safetensors:  85% 94.4M/110M [00:01<00:00, 52.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "0_26213.safetensors:  19% 10.5M/55.1M [00:00<00:00, 59.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "26214_52427.safetensors:   0% 0.00/58.4M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "104857_131071.safetensors:  17% 10.5M/60.5M [00:00<00:00, 65.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "26214_52427.safetensors:  18% 10.5M/58.4M [00:00<00:00, 104MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "26214_52427.safetensors:  38% 41.9M/110M [00:01<00:01, 46.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "0_26213.safetensors:  38% 21.0M/55.1M [00:00<00:00, 73.5MB/s]\u001b[A\u001b[A\n",
            "52428_78642.safetensors:  39% 41.9M/108M [00:00<00:00, 74.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "104857_131071.safetensors:  95% 105M/110M [00:02<00:00, 52.3MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "0_26213.safetensors:  95% 105M/110M [00:02<00:00, 41.6MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "104857_131071.safetensors:  35% 21.0M/60.5M [00:00<00:00, 69.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "78643_104856.safetensors:  19% 21.0M/111M [00:00<00:02, 37.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "0_26213.safetensors: 100% 110M/110M [00:02<00:00, 50.1MB/s]\n",
            "Download complete. Moving file to results/transcoder-llama-131k-mntss/latents/layers.14.mlp/0_26213.safetensors\n",
            "Fetching 98 files:  39% 38/98 [00:10<00:13,  4.51it/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "26214_52427.safetensors:  36% 21.0M/58.4M [00:00<00:00, 71.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "104857_131071.safetensors: 100% 110M/110M [00:02<00:00, 50.2MB/s]\n",
            "Download complete. Moving file to results/transcoder-llama-131k-mntss/latents/layers.14.mlp/104857_131071.safetensors\n",
            "Downloading 'latents/layers.15.mlp/52428_78642.safetensors' to 'results/transcoder-llama-131k-mntss/.cache/huggingface/download/latents/layers.15.mlp/D5ZAGWY4JGprrJuJg32OEAI_coI=.f74e63e65c50b234f9c84d3f721c6561ae59d6f05265b1e56c215f4038bbbc60.incomplete'\n",
            "Downloading 'latents/layers.15.mlp/78643_104856.safetensors' to 'results/transcoder-llama-131k-mntss/.cache/huggingface/download/latents/layers.15.mlp/Z1qsMB7fH8Q67YIj0ULmBJBlW_E=.ea3f96cfd7f210e552c3999f1477d6bf06ab3f819a8691d2d5353431353362f4.incomplete'\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "26214_52427.safetensors:  57% 62.9M/110M [00:01<00:00, 60.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "52428_78642.safetensors:  49% 52.4M/108M [00:00<00:00, 59.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "104857_131071.safetensors:  52% 31.5M/60.5M [00:00<00:00, 61.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "78643_104856.safetensors:  38% 41.9M/111M [00:00<00:01, 60.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "26214_52427.safetensors:  67% 73.4M/110M [00:01<00:00, 66.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "0_26213.safetensors:  76% 41.9M/55.1M [00:00<00:00, 59.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "26214_52427.safetensors:  72% 41.9M/58.4M [00:00<00:00, 80.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "52428_78642.safetensors:   0% 0.00/56.5M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "78643_104856.safetensors:   0% 0.00/56.9M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "104857_131071.safetensors:  69% 41.9M/60.5M [00:00<00:00, 54.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "26214_52427.safetensors:  77% 83.9M/110M [00:01<00:00, 66.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "0_26213.safetensors:  95% 52.4M/55.1M [00:00<00:00, 58.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "78643_104856.safetensors:  18% 10.5M/56.9M [00:00<00:00, 96.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "78643_104856.safetensors:  47% 52.4M/111M [00:01<00:01, 47.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "26214_52427.safetensors:  86% 94.4M/110M [00:01<00:00, 72.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "52428_78642.safetensors:  19% 10.5M/56.5M [00:00<00:01, 41.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "0_26213.safetensors: 100% 55.1M/55.1M [00:00<00:00, 55.4MB/s]\n",
            "Download complete. Moving file to results/transcoder-llama-131k-mntss/latents/layers.15.mlp/0_26213.safetensors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "26214_52427.safetensors:  90% 52.4M/58.4M [00:00<00:00, 54.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ADownloading 'latents/layers.15.mlp/config.json' to 'results/transcoder-llama-131k-mntss/.cache/huggingface/download/latents/layers.15.mlp/8_PA_wEVGiVa2goH2H4KQOQpvVY=.e15d0eb1fb235ccc57b1d72c5aaa2f72eced9fa2.incomplete'\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "104857_131071.safetensors: 100% 60.5M/60.5M [00:01<00:00, 57.3MB/s]\n",
            "Download complete. Moving file to results/transcoder-llama-131k-mntss/latents/layers.15.mlp/104857_131071.safetensors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "52428_78642.safetensors:  37% 21.0M/56.5M [00:00<00:00, 46.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "78643_104856.safetensors:  37% 21.0M/56.9M [00:00<00:00, 49.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "config.json: 100% 279/279 [00:00<00:00, 2.34MB/s]\n",
            "Download complete. Moving file to results/transcoder-llama-131k-mntss/latents/layers.15.mlp/config.json\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "26214_52427.safetensors:  96% 105M/110M [00:02<00:00, 56.5MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ADownloading 'latents/layers.2.mlp/104857_131071.safetensors' to 'results/transcoder-llama-131k-mntss/.cache/huggingface/download/latents/layers.2.mlp/lu--7ZbzRrZQs-kWIpm2vw7DCuk=.ed6b15b4aab58855b241794492434ee17f0a1d192787a42488c495b69026512b.incomplete'\n",
            "26214_52427.safetensors: 100% 58.4M/58.4M [00:01<00:00, 53.4MB/s]\n",
            "Downloading 'latents/layers.2.mlp/0_26213.safetensors' to 'results/transcoder-llama-131k-mntss/.cache/huggingface/download/latents/layers.2.mlp/nzlrvqDo6FcYy0VjcCkWRR0e70U=.fef26c4f23e6db3c02badac2029e63aae267a7d6713f65d20322756d7a057594.incomplete'\n",
            "Download complete. Moving file to results/transcoder-llama-131k-mntss/latents/layers.15.mlp/26214_52427.safetensors\n",
            "26214_52427.safetensors: 100% 110M/110M [00:02<00:00, 52.9MB/s]\n",
            "Download complete. Moving file to results/transcoder-llama-131k-mntss/latents/layers.14.mlp/26214_52427.safetensors\n",
            "Fetching 98 files:  41% 40/98 [00:11<00:16,  3.56it/s]\n",
            "52428_78642.safetensors:  68% 73.4M/108M [00:01<00:00, 39.8MB/s]\u001b[ADownloading 'latents/layers.2.mlp/26214_52427.safetensors' to 'results/transcoder-llama-131k-mntss/.cache/huggingface/download/latents/layers.2.mlp/DfI343hiqeb5QZh_dzGOa9U1tOI=.5916b15ecb8de19e7640c8d390dae0de9155bdaedd43ed9da95aeed17673ef4a.incomplete'\n",
            "\n",
            "\n",
            "\n",
            "78643_104856.safetensors:  66% 73.4M/111M [00:01<00:00, 50.4MB/s]\u001b[A\u001b[A\u001b[ADownloading 'latents/layers.2.mlp/52428_78642.safetensors' to 'results/transcoder-llama-131k-mntss/.cache/huggingface/download/latents/layers.2.mlp/D5ZAGWY4JGprrJuJg32OEAI_coI=.b0303b2a72b12df317a749bc52c57e62f50d98a68503c21785cead369018ccb8.incomplete'\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "52428_78642.safetensors:  74% 41.9M/56.5M [00:00<00:00, 62.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "0_26213.safetensors:   0% 0.00/108M [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "78643_104856.safetensors:  74% 41.9M/56.9M [00:00<00:00, 64.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "52428_78642.safetensors:  78% 83.9M/108M [00:01<00:00, 41.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "26214_52427.safetensors:   0% 0.00/109M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "78643_104856.safetensors:  75% 83.9M/111M [00:01<00:00, 50.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "52428_78642.safetensors:  93% 52.4M/56.5M [00:00<00:00, 65.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "0_26213.safetensors:  10% 10.5M/108M [00:00<00:01, 66.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "52428_78642.safetensors: 100% 56.5M/56.5M [00:00<00:00, 62.3MB/s]\n",
            "Download complete. Moving file to results/transcoder-llama-131k-mntss/latents/layers.15.mlp/52428_78642.safetensors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "52428_78642.safetensors:   0% 0.00/108M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "52428_78642.safetensors:  87% 94.4M/108M [00:01<00:00, 48.4MB/s]\u001b[ADownloading 'latents/layers.2.mlp/78643_104856.safetensors' to 'results/transcoder-llama-131k-mntss/.cache/huggingface/download/latents/layers.2.mlp/Z1qsMB7fH8Q67YIj0ULmBJBlW_E=.fa0f0bd32b63032831be45b8586518f06f8de21ab8afbd8016cc0b6d9b72bbd4.incomplete'\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "26214_52427.safetensors:  10% 10.5M/109M [00:00<00:01, 67.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "78643_104856.safetensors:  92% 52.4M/56.9M [00:00<00:00, 55.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "104857_131071.safetensors:   9% 10.5M/112M [00:00<00:01, 86.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "0_26213.safetensors:  29% 31.5M/108M [00:00<00:00, 112MB/s] \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "78643_104856.safetensors:  94% 105M/111M [00:01<00:00, 59.4MB/s] \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "78643_104856.safetensors: 100% 56.9M/56.9M [00:01<00:00, 51.7MB/s]\n",
            "Download complete. Moving file to results/transcoder-llama-131k-mntss/latents/layers.15.mlp/78643_104856.safetensors\n",
            "\n",
            "\n",
            "\n",
            "78643_104856.safetensors: 100% 111M/111M [00:02<00:00, 53.8MB/s]\n",
            "Download complete. Moving file to results/transcoder-llama-131k-mntss/latents/layers.14.mlp/78643_104856.safetensors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "26214_52427.safetensors:  19% 21.0M/109M [00:00<00:01, 49.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[ADownloading 'latents/layers.2.mlp/config.json' to 'results/transcoder-llama-131k-mntss/.cache/huggingface/download/latents/layers.2.mlp/8_PA_wEVGiVa2goH2H4KQOQpvVY=.e15d0eb1fb235ccc57b1d72c5aaa2f72eced9fa2.incomplete'\n",
            "\n",
            "52428_78642.safetensors:  97% 105M/108M [00:02<00:00, 43.2MB/s] \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "104857_131071.safetensors:  19% 21.0M/112M [00:00<00:01, 55.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "78643_104856.safetensors:   9% 10.5M/114M [00:00<00:01, 101MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ADownloading 'latents/layers.3.mlp/0_26213.safetensors' to 'results/transcoder-llama-131k-mntss/.cache/huggingface/download/latents/layers.3.mlp/nzlrvqDo6FcYy0VjcCkWRR0e70U=.1a25a6e4b0735229b78dc96bda8ec651ee34ff349cb00ad2f2a1c46f7683c6d3.incomplete'\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "52428_78642.safetensors:  10% 10.5M/108M [00:00<00:03, 25.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "52428_78642.safetensors: 100% 108M/108M [00:02<00:00, 45.7MB/s]\n",
            "Download complete. Moving file to results/transcoder-llama-131k-mntss/latents/layers.14.mlp/52428_78642.safetensors\n",
            "Fetching 98 files:  42% 41/98 [00:12<00:21,  2.70it/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "104857_131071.safetensors:  28% 31.5M/112M [00:00<00:01, 58.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ADownloading 'latents/layers.3.mlp/104857_131071.safetensors' to 'results/transcoder-llama-131k-mntss/.cache/huggingface/download/latents/layers.3.mlp/lu--7ZbzRrZQs-kWIpm2vw7DCuk=.7e78551f139a87e58a145908b4fb99c5eb3d442194a92ad71dea9af226badfa1.incomplete'\n",
            "\n",
            "config.json: 100% 279/279 [00:00<00:00, 1.80MB/s]\n",
            "Download complete. Moving file to results/transcoder-llama-131k-mntss/latents/layers.2.mlp/config.json\n",
            "\n",
            "\n",
            "0_26213.safetensors:  49% 52.4M/108M [00:00<00:00, 66.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "52428_78642.safetensors:  19% 21.0M/108M [00:00<00:02, 37.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ADownloading 'latents/layers.3.mlp/26214_52427.safetensors' to 'results/transcoder-llama-131k-mntss/.cache/huggingface/download/latents/layers.3.mlp/DfI343hiqeb5QZh_dzGOa9U1tOI=.e4915df7e86b6d003b7ef802ff599ca06a96bd09701ae86516a386eeee3031a4.incomplete'\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "26214_52427.safetensors:  38% 41.9M/109M [00:00<00:01, 57.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "78643_104856.safetensors:  18% 21.0M/114M [00:00<00:02, 46.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "0_26213.safetensors:   0% 0.00/108M [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "78643_104856.safetensors:  27% 31.5M/114M [00:00<00:01, 61.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "104857_131071.safetensors:   0% 0.00/108M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "104857_131071.safetensors:  37% 41.9M/112M [00:00<00:01, 47.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "0_26213.safetensors:  10% 10.5M/108M [00:00<00:01, 80.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "52428_78642.safetensors:  29% 31.5M/108M [00:00<00:01, 43.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "26214_52427.safetensors:   0% 0.00/106M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "26214_52427.safetensors:  48% 52.4M/109M [00:00<00:01, 52.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "104857_131071.safetensors:  47% 52.4M/112M [00:00<00:01, 57.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "104857_131071.safetensors:  10% 10.5M/108M [00:00<00:01, 64.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "78643_104856.safetensors:  37% 41.9M/114M [00:00<00:01, 54.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "0_26213.safetensors:  68% 73.4M/108M [00:01<00:00, 56.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "26214_52427.safetensors:  10% 10.5M/106M [00:00<00:01, 51.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "104857_131071.safetensors:  56% 62.9M/112M [00:01<00:00, 63.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "104857_131071.safetensors:  29% 31.5M/108M [00:00<00:00, 98.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "0_26213.safetensors:  78% 83.9M/108M [00:01<00:00, 58.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "52428_78642.safetensors:  39% 41.9M/108M [00:01<00:01, 36.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "26214_52427.safetensors:  67% 73.4M/109M [00:01<00:00, 55.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "104857_131071.safetensors:  65% 73.4M/112M [00:01<00:00, 60.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "78643_104856.safetensors:  46% 52.4M/114M [00:01<00:01, 48.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "26214_52427.safetensors:  20% 21.0M/106M [00:00<00:01, 44.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "0_26213.safetensors:  88% 94.4M/108M [00:01<00:00, 63.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "52428_78642.safetensors:  49% 52.4M/108M [00:01<00:01, 44.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "104857_131071.safetensors:  39% 41.9M/108M [00:00<00:00, 76.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "26214_52427.safetensors:  30% 31.5M/106M [00:00<00:01, 58.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "52428_78642.safetensors:  58% 62.9M/108M [00:01<00:00, 53.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "0_26213.safetensors:  97% 105M/108M [00:01<00:00, 63.2MB/s] \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "26214_52427.safetensors:  77% 83.9M/109M [00:01<00:00, 47.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "0_26213.safetensors:  19% 21.0M/108M [00:00<00:04, 21.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "104857_131071.safetensors:  75% 83.9M/112M [00:01<00:00, 47.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "104857_131071.safetensors:  48% 52.4M/108M [00:00<00:00, 61.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "78643_104856.safetensors:  64% 73.4M/114M [00:01<00:00, 57.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "52428_78642.safetensors:  68% 73.4M/108M [00:01<00:00, 57.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "0_26213.safetensors: 100% 108M/108M [00:01<00:00, 58.4MB/s]\n",
            "Download complete. Moving file to results/transcoder-llama-131k-mntss/latents/layers.2.mlp/0_26213.safetensors\n",
            "Fetching 98 files:  51% 50/98 [00:13<00:10,  4.80it/s]Downloading 'latents/layers.3.mlp/52428_78642.safetensors' to 'results/transcoder-llama-131k-mntss/.cache/huggingface/download/latents/layers.3.mlp/D5ZAGWY4JGprrJuJg32OEAI_coI=.159c8af3d2d04f33650bc4fa4c60f361b05ff9ebb870d2eb7ddbeb6c0833d77b.incomplete'\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "52428_78642.safetensors:  78% 83.9M/108M [00:01<00:00, 61.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "78643_104856.safetensors:  73% 83.9M/114M [00:01<00:00, 53.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "104857_131071.safetensors:  68% 73.4M/108M [00:01<00:00, 67.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "0_26213.safetensors:  29% 31.5M/108M [00:01<00:02, 26.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "26214_52427.safetensors:  50% 52.4M/106M [00:01<00:01, 49.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "52428_78642.safetensors:  88% 94.4M/108M [00:01<00:00, 66.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "26214_52427.safetensors: 100% 109M/109M [00:02<00:00, 53.8MB/s]\n",
            "Download complete. Moving file to results/transcoder-llama-131k-mntss/latents/layers.2.mlp/26214_52427.safetensors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "78643_104856.safetensors:  82% 94.4M/114M [00:01<00:00, 56.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "52428_78642.safetensors:   0% 0.00/112M [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "26214_52427.safetensors:  59% 62.9M/106M [00:01<00:00, 57.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ADownloading 'latents/layers.3.mlp/78643_104856.safetensors' to 'results/transcoder-llama-131k-mntss/.cache/huggingface/download/latents/layers.3.mlp/Z1qsMB7fH8Q67YIj0ULmBJBlW_E=.32d9edbc1335d708c82183d048361a13cae2eb51f38639b4fbebc19382642d72.incomplete'\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "104857_131071.safetensors:  93% 105M/112M [00:02<00:00, 45.4MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "0_26213.safetensors:  39% 41.9M/108M [00:01<00:02, 31.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "78643_104856.safetensors:  92% 105M/114M [00:01<00:00, 62.7MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "52428_78642.safetensors:   9% 10.5M/112M [00:00<00:01, 81.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "52428_78642.safetensors:  97% 105M/108M [00:02<00:00, 54.4MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "52428_78642.safetensors: 100% 108M/108M [00:02<00:00, 49.8MB/s]\n",
            "Download complete. Moving file to results/transcoder-llama-131k-mntss/latents/layers.2.mlp/52428_78642.safetensors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "104857_131071.safetensors: 100% 112M/112M [00:02<00:00, 50.3MB/s]\n",
            "Download complete. Moving file to results/transcoder-llama-131k-mntss/latents/layers.2.mlp/104857_131071.safetensors\n",
            "Fetching 98 files:  52% 51/98 [00:13<00:11,  4.14it/s]Downloading 'latents/layers.3.mlp/config.json' to 'results/transcoder-llama-131k-mntss/.cache/huggingface/download/latents/layers.3.mlp/8_PA_wEVGiVa2goH2H4KQOQpvVY=.e15d0eb1fb235ccc57b1d72c5aaa2f72eced9fa2.incomplete'\n",
            "\n",
            "\n",
            "\n",
            "104857_131071.safetensors:  78% 83.9M/108M [00:01<00:00, 47.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "78643_104856.safetensors:   0% 0.00/105M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[ADownloading 'latents/layers.4.mlp/0_26213.safetensors' to 'results/transcoder-llama-131k-mntss/.cache/huggingface/download/latents/layers.4.mlp/nzlrvqDo6FcYy0VjcCkWRR0e70U=.33d6dd63cfd18c83ab7055016cd9d039a5b1ce553665b1096381cd87af55ed02.incomplete'\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "config.json: 100% 279/279 [00:00<00:00, 3.10MB/s]\n",
            "Download complete. Moving file to results/transcoder-llama-131k-mntss/latents/layers.3.mlp/config.json\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "78643_104856.safetensors: 100% 114M/114M [00:02<00:00, 55.3MB/s]\n",
            "Download complete. Moving file to results/transcoder-llama-131k-mntss/latents/layers.2.mlp/78643_104856.safetensors\n",
            "Fetching 98 files:  55% 54/98 [00:14<00:07,  5.52it/s]\n",
            "0_26213.safetensors:  48% 52.4M/108M [00:01<00:01, 33.9MB/s]\u001b[ADownloading 'latents/layers.4.mlp/104857_131071.safetensors' to 'results/transcoder-llama-131k-mntss/.cache/huggingface/download/latents/layers.4.mlp/lu--7ZbzRrZQs-kWIpm2vw7DCuk=.2183042332e1e459bb20af6e0906f79780a950e998491e601dca999ba2b8d3ca.incomplete'\n",
            "\n",
            "\n",
            "52428_78642.safetensors:  19% 21.0M/112M [00:00<00:01, 47.9MB/s]\u001b[A\u001b[ADownloading 'latents/layers.4.mlp/26214_52427.safetensors' to 'results/transcoder-llama-131k-mntss/.cache/huggingface/download/latents/layers.4.mlp/DfI343hiqeb5QZh_dzGOa9U1tOI=.6e9403eb94f29221ccc65b64ac079f8757e6176430070499b1fe2913d07bcb34.incomplete'\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "26214_52427.safetensors:  79% 83.9M/106M [00:01<00:00, 52.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "78643_104856.safetensors:  10% 10.5M/105M [00:00<00:01, 65.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "0_26213.safetensors:  58% 62.9M/108M [00:01<00:01, 44.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "0_26213.safetensors:   0% 0.00/112M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "26214_52427.safetensors:  89% 94.4M/106M [00:01<00:00, 60.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "104857_131071.safetensors:  87% 94.4M/108M [00:01<00:00, 44.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "78643_104856.safetensors:  20% 21.0M/105M [00:00<00:01, 76.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "52428_78642.safetensors:  28% 31.5M/112M [00:00<00:01, 51.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "26214_52427.safetensors:   0% 0.00/110M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "0_26213.safetensors:   9% 10.5M/112M [00:00<00:00, 103MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "104857_131071.safetensors:   0% 0.00/109M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "52428_78642.safetensors:  37% 41.9M/112M [00:00<00:01, 61.5MB/s]\u001b[A\u001b[A\n",
            "0_26213.safetensors:  68% 73.4M/108M [00:02<00:00, 42.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "78643_104856.safetensors:  40% 41.9M/105M [00:00<00:00, 92.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "26214_52427.safetensors:  10% 10.5M/110M [00:00<00:02, 48.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "104857_131071.safetensors:  97% 105M/108M [00:02<00:00, 40.7MB/s] \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "52428_78642.safetensors:  47% 52.4M/112M [00:00<00:00, 61.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "26214_52427.safetensors: 100% 106M/106M [00:02<00:00, 50.9MB/s]\n",
            "Download complete. Moving file to results/transcoder-llama-131k-mntss/latents/layers.3.mlp/26214_52427.safetensors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "78643_104856.safetensors:  50% 52.4M/105M [00:00<00:00, 71.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "104857_131071.safetensors:  10% 10.5M/109M [00:00<00:03, 31.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "0_26213.safetensors:  19% 21.0M/112M [00:00<00:02, 39.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "0_26213.safetensors:  77% 83.9M/108M [00:02<00:00, 40.4MB/s]\u001b[ADownloading 'latents/layers.4.mlp/52428_78642.safetensors' to 'results/transcoder-llama-131k-mntss/.cache/huggingface/download/latents/layers.4.mlp/D5ZAGWY4JGprrJuJg32OEAI_coI=.cef11caad2879f13ed36b4c2d1bf436eec4603864df6c6bb94673883894a5af4.incomplete'\n",
            "104857_131071.safetensors: 100% 108M/108M [00:02<00:00, 47.2MB/s]\n",
            "Download complete. Moving file to results/transcoder-llama-131k-mntss/latents/layers.3.mlp/104857_131071.safetensors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "0_26213.safetensors:  38% 41.9M/112M [00:00<00:00, 79.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "26214_52427.safetensors:  19% 21.0M/110M [00:00<00:02, 37.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ADownloading 'latents/layers.4.mlp/78643_104856.safetensors' to 'results/transcoder-llama-131k-mntss/.cache/huggingface/download/latents/layers.4.mlp/Z1qsMB7fH8Q67YIj0ULmBJBlW_E=.43b49f1d88cb622a1016f897d4db6bd20a24c6f9ba64f3034f4d7e8450247d42.incomplete'\n",
            "\n",
            "\n",
            "52428_78642.safetensors:  65% 73.4M/112M [00:01<00:00, 61.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "0_26213.safetensors:  56% 62.9M/112M [00:00<00:00, 96.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "26214_52427.safetensors:  29% 31.5M/110M [00:00<00:01, 51.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "78643_104856.safetensors:  70% 73.4M/105M [00:01<00:00, 69.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "104857_131071.safetensors:  19% 21.0M/109M [00:00<00:02, 32.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "0_26213.safetensors:  97% 105M/108M [00:02<00:00, 49.6MB/s] \u001b[A\n",
            "\n",
            "\n",
            "78643_104856.safetensors:   0% 0.00/110M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "0_26213.safetensors: 100% 108M/108M [00:02<00:00, 39.0MB/s]\n",
            "Download complete. Moving file to results/transcoder-llama-131k-mntss/latents/layers.3.mlp/0_26213.safetensors\n",
            "Fetching 98 files:  57% 56/98 [00:15<00:11,  3.78it/s]\n",
            "\n",
            "\n",
            "\n",
            "78643_104856.safetensors:  80% 83.9M/105M [00:01<00:00, 64.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "104857_131071.safetensors:  29% 31.5M/109M [00:00<00:01, 39.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "52428_78642.safetensors:  75% 83.9M/112M [00:01<00:00, 50.8MB/s]\u001b[A\u001b[ADownloading 'latents/layers.4.mlp/config.json' to 'results/transcoder-llama-131k-mntss/.cache/huggingface/download/latents/layers.4.mlp/8_PA_wEVGiVa2goH2H4KQOQpvVY=.e15d0eb1fb235ccc57b1d72c5aaa2f72eced9fa2.incomplete'\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "52428_78642.safetensors:  10% 10.5M/109M [00:00<00:01, 89.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "config.json: 100% 279/279 [00:00<00:00, 2.48MB/s]\n",
            "Download complete. Moving file to results/transcoder-llama-131k-mntss/latents/layers.4.mlp/config.json\n",
            "\n",
            "\n",
            "\n",
            "78643_104856.safetensors:  10% 10.5M/110M [00:00<00:01, 62.8MB/s]\u001b[A\u001b[A\u001b[ADownloading 'latents/layers.5.mlp/0_26213.safetensors' to 'results/transcoder-llama-131k-mntss/.cache/huggingface/download/latents/layers.5.mlp/nzlrvqDo6FcYy0VjcCkWRR0e70U=.794495a846e12b320bc8d3f63173a053827a6ac3c10b0603a4391fe11eb45014.incomplete'\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "52428_78642.safetensors:  19% 21.0M/109M [00:00<00:01, 78.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "104857_131071.safetensors:  39% 41.9M/109M [00:01<00:01, 44.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "78643_104856.safetensors: 100% 105M/105M [00:01<00:00, 72.4MB/s]\n",
            "Download complete. Moving file to results/transcoder-llama-131k-mntss/latents/layers.3.mlp/78643_104856.safetensors\n",
            "Downloading 'latents/layers.5.mlp/104857_131071.safetensors' to 'results/transcoder-llama-131k-mntss/.cache/huggingface/download/latents/layers.5.mlp/lu--7ZbzRrZQs-kWIpm2vw7DCuk=.6135f2328b01947b3f6ddd51444149ae1da1d5eb722969f7a9c6597de6ffaa53.incomplete'\n",
            "\n",
            "\n",
            "52428_78642.safetensors:  93% 105M/112M [00:01<00:00, 60.0MB/s] \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "26214_52427.safetensors:  48% 52.4M/110M [00:01<00:01, 43.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "78643_104856.safetensors:  19% 21.0M/110M [00:00<00:02, 44.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "104857_131071.safetensors:  48% 52.4M/109M [00:01<00:01, 48.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "0_26213.safetensors:   0% 0.00/98.0M [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "0_26213.safetensors:  75% 83.9M/112M [00:01<00:00, 53.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "104857_131071.safetensors:  58% 62.9M/109M [00:01<00:00, 55.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "52428_78642.safetensors:  38% 41.9M/109M [00:00<00:00, 68.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "0_26213.safetensors:  11% 10.5M/98.0M [00:00<00:01, 70.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "104857_131071.safetensors:   0% 0.00/96.7M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "52428_78642.safetensors: 100% 112M/112M [00:02<00:00, 52.9MB/s]\n",
            "Download complete. Moving file to results/transcoder-llama-131k-mntss/latents/layers.3.mlp/52428_78642.safetensors\n",
            "Fetching 98 files:  60% 59/98 [00:15<00:09,  4.03it/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "26214_52427.safetensors:  67% 73.4M/110M [00:01<00:00, 51.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "104857_131071.safetensors:  67% 73.4M/109M [00:01<00:00, 62.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ADownloading 'latents/layers.5.mlp/26214_52427.safetensors' to 'results/transcoder-llama-131k-mntss/.cache/huggingface/download/latents/layers.5.mlp/DfI343hiqeb5QZh_dzGOa9U1tOI=.95becd39d590801f1dfc1d74c2c7026224c310e66c4ac5782adfb3c2f198d2d0.incomplete'\n",
            "\n",
            "\n",
            "\n",
            "78643_104856.safetensors:  29% 31.5M/110M [00:00<00:02, 38.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "52428_78642.safetensors:  48% 52.4M/109M [00:00<00:00, 65.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "104857_131071.safetensors:  11% 10.5M/96.7M [00:00<00:01, 83.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "0_26213.safetensors:  21% 21.0M/98.0M [00:00<00:01, 66.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "0_26213.safetensors:  94% 105M/112M [00:01<00:00, 56.8MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "0_26213.safetensors: 100% 112M/112M [00:01<00:00, 62.2MB/s]\n",
            "Download complete. Moving file to results/transcoder-llama-131k-mntss/latents/layers.4.mlp/0_26213.safetensors\n",
            "Fetching 98 files:  63% 62/98 [00:16<00:06,  5.21it/s]\n",
            "\n",
            "\n",
            "\n",
            "104857_131071.safetensors:  22% 21.0M/96.7M [00:00<00:00, 83.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[ADownloading 'latents/layers.5.mlp/52428_78642.safetensors' to 'results/transcoder-llama-131k-mntss/.cache/huggingface/download/latents/layers.5.mlp/D5ZAGWY4JGprrJuJg32OEAI_coI=.7a12a796060f7c006f6404466c884ecf6bae4116e19afb7c24ded08098d3877b.incomplete'\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "26214_52427.safetensors:  76% 83.9M/110M [00:01<00:00, 49.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "78643_104856.safetensors:  38% 41.9M/110M [00:00<00:01, 42.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "26214_52427.safetensors:   0% 0.00/96.8M [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "104857_131071.safetensors:  87% 94.4M/109M [00:01<00:00, 61.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "0_26213.safetensors:  43% 41.9M/98.0M [00:00<00:00, 71.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "104857_131071.safetensors:  43% 41.9M/96.7M [00:00<00:00, 84.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "104857_131071.safetensors:  96% 105M/109M [00:01<00:00, 67.4MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "52428_78642.safetensors:   0% 0.00/97.0M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "104857_131071.safetensors: 100% 109M/109M [00:01<00:00, 54.5MB/s]\n",
            "Download complete. Moving file to results/transcoder-llama-131k-mntss/latents/layers.4.mlp/104857_131071.safetensors\n",
            "Fetching 98 files:  64% 63/98 [00:16<00:07,  4.72it/s]\n",
            "\n",
            "\n",
            "78643_104856.safetensors:  48% 52.4M/110M [00:01<00:01, 40.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "26214_52427.safetensors:  95% 105M/110M [00:02<00:00, 55.5MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "0_26213.safetensors:  53% 52.4M/98.0M [00:00<00:00, 64.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "104857_131071.safetensors:  54% 52.4M/96.7M [00:00<00:00, 79.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[ADownloading 'latents/layers.5.mlp/78643_104856.safetensors' to 'results/transcoder-llama-131k-mntss/.cache/huggingface/download/latents/layers.5.mlp/Z1qsMB7fH8Q67YIj0ULmBJBlW_E=.df77a500a80674f6d3d2a5a6a4bfd461529182c2cf87f095c110961e9a252ff8.incomplete'\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "52428_78642.safetensors:  67% 73.4M/109M [00:01<00:00, 47.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "26214_52427.safetensors:  22% 21.0M/96.8M [00:00<00:01, 61.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "78643_104856.safetensors:  57% 62.9M/110M [00:01<00:00, 50.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "26214_52427.safetensors: 100% 110M/110M [00:02<00:00, 49.7MB/s]\n",
            "Download complete. Moving file to results/transcoder-llama-131k-mntss/latents/layers.4.mlp/26214_52427.safetensors\n",
            "Fetching 98 files:  65% 64/98 [00:16<00:06,  4.86it/s]Downloading 'latents/layers.5.mlp/config.json' to 'results/transcoder-llama-131k-mntss/.cache/huggingface/download/latents/layers.5.mlp/8_PA_wEVGiVa2goH2H4KQOQpvVY=.e15d0eb1fb235ccc57b1d72c5aaa2f72eced9fa2.incomplete'\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "52428_78642.safetensors:  22% 21.0M/97.0M [00:00<00:01, 58.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "78643_104856.safetensors:  67% 73.4M/110M [00:01<00:00, 51.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "config.json: 100% 279/279 [00:00<00:00, 2.17MB/s]\n",
            "Download complete. Moving file to results/transcoder-llama-131k-mntss/latents/layers.5.mlp/config.json\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "52428_78642.safetensors:  77% 83.9M/109M [00:01<00:00, 46.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "104857_131071.safetensors:  76% 73.4M/96.7M [00:00<00:00, 75.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[ADownloading 'latents/layers.6.mlp/0_26213.safetensors' to 'results/transcoder-llama-131k-mntss/.cache/huggingface/download/latents/layers.6.mlp/nzlrvqDo6FcYy0VjcCkWRR0e70U=.9ec69d6bc1250f74da4d130192897379c00cb5940726b24f53040555ca0e90ad.incomplete'\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "78643_104856.safetensors:   0% 0.00/98.5M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "26214_52427.safetensors:  33% 31.5M/96.8M [00:00<00:01, 43.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "52428_78642.safetensors:  86% 94.4M/109M [00:01<00:00, 51.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "52428_78642.safetensors:  43% 41.9M/97.0M [00:00<00:00, 77.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "104857_131071.safetensors:  87% 83.9M/96.7M [00:01<00:00, 66.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "0_26213.safetensors:  75% 73.4M/98.0M [00:01<00:00, 45.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "78643_104856.safetensors:  76% 83.9M/110M [00:01<00:00, 45.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "0_26213.safetensors:   0% 0.00/97.0M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "26214_52427.safetensors:  43% 41.9M/96.8M [00:00<00:01, 41.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "52428_78642.safetensors:  54% 52.4M/97.0M [00:00<00:00, 62.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "0_26213.safetensors:  11% 10.5M/97.0M [00:00<00:00, 101MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "104857_131071.safetensors: 100% 96.7M/96.7M [00:01<00:00, 67.7MB/s]\n",
            "Download complete. Moving file to results/transcoder-llama-131k-mntss/latents/layers.5.mlp/104857_131071.safetensors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "78643_104856.safetensors:  11% 10.5M/98.5M [00:00<00:03, 23.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ADownloading 'latents/layers.6.mlp/104857_131071.safetensors' to 'results/transcoder-llama-131k-mntss/.cache/huggingface/download/latents/layers.6.mlp/lu--7ZbzRrZQs-kWIpm2vw7DCuk=.eab2a4f336490d71ca26f78a3e49faf4406870ac2003d5ae23e87a60b08773c7.incomplete'\n",
            "\n",
            "\n",
            "\n",
            "78643_104856.safetensors:  95% 105M/110M [00:02<00:00, 51.8MB/s] \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "78643_104856.safetensors: 100% 110M/110M [00:02<00:00, 49.3MB/s]\n",
            "Download complete. Moving file to results/transcoder-llama-131k-mntss/latents/layers.4.mlp/78643_104856.safetensors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "52428_78642.safetensors:  96% 105M/109M [00:02<00:00, 36.4MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ADownloading 'latents/layers.6.mlp/26214_52427.safetensors' to 'results/transcoder-llama-131k-mntss/.cache/huggingface/download/latents/layers.6.mlp/DfI343hiqeb5QZh_dzGOa9U1tOI=.6d94e5b6ce554b61f073c5776db0bb6212510bba239d0b8570f851e40584902e.incomplete'\n",
            "\n",
            "\n",
            "26214_52427.safetensors:  54% 52.4M/96.8M [00:01<00:01, 35.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "78643_104856.safetensors:  21% 21.0M/98.5M [00:00<00:02, 32.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "0_26213.safetensors:  86% 83.9M/98.0M [00:01<00:00, 32.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "52428_78642.safetensors: 100% 109M/109M [00:02<00:00, 46.1MB/s]\n",
            "Download complete. Moving file to results/transcoder-llama-131k-mntss/latents/layers.4.mlp/52428_78642.safetensors\n",
            "Fetching 98 files:  66% 65/98 [00:17<00:11,  2.91it/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "52428_78642.safetensors:  76% 73.4M/97.0M [00:01<00:00, 56.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ADownloading 'latents/layers.6.mlp/52428_78642.safetensors' to 'results/transcoder-llama-131k-mntss/.cache/huggingface/download/latents/layers.6.mlp/D5ZAGWY4JGprrJuJg32OEAI_coI=.38e6298c5390a217a9b0d60d137f0fb40e50749a50002f9e6880a32ed16cf477.incomplete'\n",
            "\n",
            "0_26213.safetensors:  96% 94.4M/98.0M [00:01<00:00, 41.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "0_26213.safetensors:  32% 31.5M/97.0M [00:00<00:01, 55.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "78643_104856.safetensors:  32% 31.5M/98.5M [00:00<00:01, 44.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "104857_131071.safetensors:  11% 10.5M/94.3M [00:00<00:01, 76.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "26214_52427.safetensors:   0% 0.00/96.4M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "52428_78642.safetensors:  87% 83.9M/97.0M [00:01<00:00, 59.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "26214_52427.safetensors:  76% 73.4M/96.8M [00:01<00:00, 49.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "78643_104856.safetensors:  43% 41.9M/98.5M [00:00<00:01, 55.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "104857_131071.safetensors:  22% 21.0M/94.3M [00:00<00:00, 84.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "52428_78642.safetensors:   0% 0.00/94.1M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "0_26213.safetensors: 100% 98.0M/98.0M [00:02<00:00, 44.8MB/s]\n",
            "Download complete. Moving file to results/transcoder-llama-131k-mntss/latents/layers.5.mlp/0_26213.safetensors\n",
            "Fetching 98 files:  69% 68/98 [00:17<00:07,  4.23it/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "52428_78642.safetensors:  97% 94.4M/97.0M [00:01<00:00, 65.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "26214_52427.safetensors:  11% 10.5M/96.4M [00:00<00:01, 60.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[ADownloading 'latents/layers.6.mlp/78643_104856.safetensors' to 'results/transcoder-llama-131k-mntss/.cache/huggingface/download/latents/layers.6.mlp/Z1qsMB7fH8Q67YIj0ULmBJBlW_E=.cb40fae3f7ece6a05b1360b12c2e8f7b6f6fa3c1a90a94a9986357b8ea4a3bcd.incomplete'\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "52428_78642.safetensors: 100% 97.0M/97.0M [00:01<00:00, 62.2MB/s]\n",
            "Download complete. Moving file to results/transcoder-llama-131k-mntss/latents/layers.5.mlp/52428_78642.safetensors\n",
            "Downloading 'latents/layers.6.mlp/config.json' to 'results/transcoder-llama-131k-mntss/.cache/huggingface/download/latents/layers.6.mlp/8_PA_wEVGiVa2goH2H4KQOQpvVY=.e15d0eb1fb235ccc57b1d72c5aaa2f72eced9fa2.incomplete'\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "26214_52427.safetensors:  22% 21.0M/96.4M [00:00<00:01, 72.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "104857_131071.safetensors:  44% 41.9M/94.3M [00:00<00:00, 86.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "78643_104856.safetensors:  53% 52.4M/98.5M [00:01<00:00, 49.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "52428_78642.safetensors:  22% 21.0M/94.1M [00:00<00:00, 95.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "config.json: 100% 279/279 [00:00<00:00, 2.09MB/s]\n",
            "Download complete. Moving file to results/transcoder-llama-131k-mntss/latents/layers.6.mlp/config.json\n",
            "\n",
            "\n",
            "26214_52427.safetensors:  87% 83.9M/96.8M [00:01<00:00, 43.3MB/s]\u001b[A\u001b[ADownloading 'latents/layers.7.mlp/0_26213.safetensors' to 'results/transcoder-llama-131k-mntss/.cache/huggingface/download/latents/layers.7.mlp/nzlrvqDo6FcYy0VjcCkWRR0e70U=.2f81071320eb87371ba604950932a9d5fc2e25ffacbacac22063c0c24a4138ca.incomplete'\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "78643_104856.safetensors:  64% 62.9M/98.5M [00:01<00:00, 57.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "78643_104856.safetensors:   0% 0.00/96.7M [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "0_26213.safetensors:  54% 52.4M/97.0M [00:01<00:01, 41.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "104857_131071.safetensors:  56% 52.4M/94.3M [00:00<00:00, 69.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "52428_78642.safetensors:  45% 41.9M/94.1M [00:00<00:00, 101MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "26214_52427.safetensors:  33% 31.5M/96.4M [00:00<00:01, 53.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "26214_52427.safetensors: 100% 96.8M/96.8M [00:02<00:00, 45.9MB/s]\n",
            "Download complete. Moving file to results/transcoder-llama-131k-mntss/latents/layers.5.mlp/26214_52427.safetensors\n",
            "Fetching 98 files:  71% 70/98 [00:18<00:06,  4.38it/s]Downloading 'latents/layers.7.mlp/104857_131071.safetensors' to 'results/transcoder-llama-131k-mntss/.cache/huggingface/download/latents/layers.7.mlp/lu--7ZbzRrZQs-kWIpm2vw7DCuk=.ecd4a63280e8404c5bbc7e14fab0e0efe89f178c4a7ff93d240f89f9c699f136.incomplete'\n",
            "\n",
            "\n",
            "0_26213.safetensors:   0% 0.00/93.1M [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "78643_104856.safetensors:  75% 73.4M/98.5M [00:01<00:00, 52.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "78643_104856.safetensors:  11% 10.5M/96.7M [00:00<00:01, 54.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "52428_78642.safetensors:  56% 52.4M/94.1M [00:00<00:00, 88.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "26214_52427.safetensors:  43% 41.9M/96.4M [00:00<00:00, 57.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "0_26213.safetensors:  11% 10.5M/93.1M [00:00<00:01, 67.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "0_26213.safetensors:  76% 73.4M/97.0M [00:01<00:00, 49.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "78643_104856.safetensors:  22% 21.0M/96.7M [00:00<00:01, 53.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "52428_78642.safetensors:  78% 73.4M/94.1M [00:00<00:00, 96.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "104857_131071.safetensors:   0% 0.00/93.1M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "26214_52427.safetensors:  54% 52.4M/96.4M [00:00<00:00, 50.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "0_26213.safetensors:  23% 21.0M/93.1M [00:00<00:01, 54.1MB/s]\u001b[A\u001b[A\n",
            "78643_104856.safetensors:  33% 31.5M/96.7M [00:00<00:01, 60.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "104857_131071.safetensors:  78% 73.4M/94.3M [00:01<00:00, 53.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "78643_104856.safetensors:  85% 83.9M/98.5M [00:01<00:00, 41.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "104857_131071.safetensors:  11% 10.5M/93.1M [00:00<00:01, 77.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "0_26213.safetensors:  86% 83.9M/97.0M [00:01<00:00, 44.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "52428_78642.safetensors:  89% 83.9M/94.1M [00:01<00:00, 70.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "78643_104856.safetensors:  96% 94.4M/98.5M [00:02<00:00, 48.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "52428_78642.safetensors: 100% 94.1M/94.1M [00:01<00:00, 85.8MB/s]\n",
            "Download complete. Moving file to results/transcoder-llama-131k-mntss/latents/layers.6.mlp/52428_78642.safetensors\n",
            "Downloading 'latents/layers.7.mlp/26214_52427.safetensors' to 'results/transcoder-llama-131k-mntss/.cache/huggingface/download/latents/layers.7.mlp/DfI343hiqeb5QZh_dzGOa9U1tOI=.00f17cbecc6bd76d74dc44e107d5649347d2a6e6be132e48969dbf44551c49df.incomplete'\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "104857_131071.safetensors:  23% 21.0M/93.1M [00:00<00:01, 55.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "0_26213.safetensors:  45% 41.9M/93.1M [00:00<00:00, 58.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "104857_131071.safetensors:  89% 83.9M/94.3M [00:01<00:00, 45.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "26214_52427.safetensors:  76% 73.4M/96.4M [00:01<00:00, 49.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "78643_104856.safetensors: 100% 98.5M/98.5M [00:02<00:00, 41.6MB/s]\n",
            "Download complete. Moving file to results/transcoder-llama-131k-mntss/latents/layers.5.mlp/78643_104856.safetensors\n",
            "Fetching 98 files:  73% 72/98 [00:19<00:07,  3.34it/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "26214_52427.safetensors:   0% 0.00/93.9M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "0_26213.safetensors:  56% 52.4M/93.1M [00:00<00:00, 55.4MB/s]\u001b[A\u001b[ADownloading 'latents/layers.7.mlp/52428_78642.safetensors' to 'results/transcoder-llama-131k-mntss/.cache/huggingface/download/latents/layers.7.mlp/D5ZAGWY4JGprrJuJg32OEAI_coI=.ba1ddef3f8ee010e932fa74853147bb564cf9ef07ec73310b2f525c946be3283.incomplete'\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "0_26213.safetensors: 100% 97.0M/97.0M [00:02<00:00, 45.2MB/s]\n",
            "Download complete. Moving file to results/transcoder-llama-131k-mntss/latents/layers.6.mlp/0_26213.safetensors\n",
            "\n",
            "\n",
            "\n",
            "104857_131071.safetensors: 100% 94.3M/94.3M [00:01<00:00, 45.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "78643_104856.safetensors:  54% 52.4M/96.7M [00:01<00:00, 46.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "104857_131071.safetensors: 100% 94.3M/94.3M [00:01<00:00, 53.2MB/s]\n",
            "Download complete. Moving file to results/transcoder-llama-131k-mntss/latents/layers.6.mlp/104857_131071.safetensors\n",
            "Downloading 'latents/layers.7.mlp/78643_104856.safetensors' to 'results/transcoder-llama-131k-mntss/.cache/huggingface/download/latents/layers.7.mlp/Z1qsMB7fH8Q67YIj0ULmBJBlW_E=.c2bc3f9ad9d6b414802c0f928ec604e20326932ff51beb461694dc51e2aec3f9.incomplete'\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "26214_52427.safetensors:  11% 10.5M/93.9M [00:00<00:01, 77.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ADownloading 'latents/layers.7.mlp/config.json' to 'results/transcoder-llama-131k-mntss/.cache/huggingface/download/latents/layers.7.mlp/8_PA_wEVGiVa2goH2H4KQOQpvVY=.e15d0eb1fb235ccc57b1d72c5aaa2f72eced9fa2.incomplete'\n",
            "\n",
            "\n",
            "\n",
            "config.json: 100% 279/279 [00:00<00:00, 2.47MB/s]\n",
            "Download complete. Moving file to results/transcoder-llama-131k-mntss/latents/layers.7.mlp/config.json\n",
            "\n",
            "\n",
            "0_26213.safetensors:  68% 62.9M/93.1M [00:01<00:00, 56.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "104857_131071.safetensors:  45% 41.9M/93.1M [00:00<00:01, 49.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ADownloading 'latents/layers.8.mlp/0_26213.safetensors' to 'results/transcoder-llama-131k-mntss/.cache/huggingface/download/latents/layers.8.mlp/nzlrvqDo6FcYy0VjcCkWRR0e70U=.06cfee68d89c111f0dbc4475e7c8e285c35a47e155fe66829684064e981ad8f5.incomplete'\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "26214_52427.safetensors: 100% 96.4M/96.4M [00:01<00:00, 54.1MB/s]\n",
            "Download complete. Moving file to results/transcoder-llama-131k-mntss/latents/layers.6.mlp/26214_52427.safetensors\n",
            "Fetching 98 files:  78% 76/98 [00:19<00:04,  5.14it/s]Downloading 'latents/layers.8.mlp/104857_131071.safetensors' to 'results/transcoder-llama-131k-mntss/.cache/huggingface/download/latents/layers.8.mlp/lu--7ZbzRrZQs-kWIpm2vw7DCuk=.8e5ea83c00be981c740a73ba30158aa98aa4a86e98c34b8f7aa5f31e7444f43c.incomplete'\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "26214_52427.safetensors:  22% 21.0M/93.9M [00:00<00:01, 60.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "78643_104856.safetensors:  76% 73.4M/96.7M [00:01<00:00, 56.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "52428_78642.safetensors:   0% 0.00/93.9M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "0_26213.safetensors:   0% 0.00/91.1M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "78643_104856.safetensors:   0% 0.00/93.3M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "26214_52427.safetensors:  33% 31.5M/93.9M [00:00<00:00, 64.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "78643_104856.safetensors:  87% 83.9M/96.7M [00:01<00:00, 58.0MB/s]\u001b[A\n",
            "\n",
            "0_26213.safetensors:  79% 73.4M/93.1M [00:01<00:00, 43.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "104857_131071.safetensors:   0% 0.00/92.5M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "0_26213.safetensors:  12% 10.5M/91.1M [00:00<00:00, 82.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "78643_104856.safetensors:  11% 10.5M/93.3M [00:00<00:01, 62.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "104857_131071.safetensors:  56% 52.4M/93.1M [00:01<00:01, 37.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "26214_52427.safetensors:  45% 41.9M/93.9M [00:00<00:00, 57.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "104857_131071.safetensors:  11% 10.5M/92.5M [00:00<00:01, 70.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "0_26213.safetensors:  35% 31.5M/91.1M [00:00<00:00, 106MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "78643_104856.safetensors: 100% 96.7M/96.7M [00:01<00:00, 53.6MB/s]\n",
            "Download complete. Moving file to results/transcoder-llama-131k-mntss/latents/layers.6.mlp/78643_104856.safetensors\n",
            "Fetching 98 files:  80% 78/98 [00:19<00:04,  4.78it/s]\n",
            "\n",
            "\n",
            "52428_78642.safetensors:  11% 10.5M/93.9M [00:00<00:03, 27.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "78643_104856.safetensors:  34% 31.5M/93.3M [00:00<00:00, 88.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ADownloading 'latents/layers.8.mlp/26214_52427.safetensors' to 'results/transcoder-llama-131k-mntss/.cache/huggingface/download/latents/layers.8.mlp/DfI343hiqeb5QZh_dzGOa9U1tOI=.5705b060a732d03d1f4a49a1e5a0acdeffca781bab4c8f05fd9b3148cf35e0f0.incomplete'\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "104857_131071.safetensors:  79% 73.4M/93.1M [00:01<00:00, 51.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "26214_52427.safetensors:  56% 52.4M/93.9M [00:00<00:00, 49.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "0_26213.safetensors:  46% 41.9M/91.1M [00:00<00:00, 75.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "104857_131071.safetensors:  23% 21.0M/92.5M [00:00<00:01, 46.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "52428_78642.safetensors:  22% 21.0M/93.9M [00:00<00:01, 38.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "26214_52427.safetensors:  78% 73.4M/93.9M [00:01<00:00, 71.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "26214_52427.safetensors:   0% 0.00/89.6M [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "\n",
            "52428_78642.safetensors:  33% 31.5M/93.9M [00:00<00:01, 51.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "78643_104856.safetensors:  56% 52.4M/93.3M [00:00<00:00, 72.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "0_26213.safetensors:  90% 83.9M/93.1M [00:02<00:00, 29.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "52428_78642.safetensors:  45% 41.9M/93.9M [00:00<00:00, 63.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "0_26213.safetensors:  58% 52.4M/91.1M [00:00<00:00, 57.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "104857_131071.safetensors:  45% 41.9M/92.5M [00:00<00:00, 62.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "104857_131071.safetensors:  90% 83.9M/93.1M [00:01<00:00, 41.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "26214_52427.safetensors:  12% 10.5M/89.6M [00:00<00:01, 58.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "52428_78642.safetensors:  67% 62.9M/93.9M [00:00<00:00, 88.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "104857_131071.safetensors:  57% 52.4M/92.5M [00:00<00:00, 64.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "26214_52427.safetensors:  89% 83.9M/93.9M [00:01<00:00, 55.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "0_26213.safetensors:  81% 73.4M/91.1M [00:01<00:00, 71.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "0_26213.safetensors: 100% 93.1M/93.1M [00:02<00:00, 39.2MB/s]\n",
            "Download complete. Moving file to results/transcoder-llama-131k-mntss/latents/layers.7.mlp/0_26213.safetensors\n",
            "Fetching 98 files:  82% 80/98 [00:20<00:04,  4.03it/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "104857_131071.safetensors: 100% 93.1M/93.1M [00:02<00:00, 44.1MB/s]\n",
            "Download complete. Moving file to results/transcoder-llama-131k-mntss/latents/layers.7.mlp/104857_131071.safetensors\n",
            "\n",
            "\n",
            "\n",
            "52428_78642.safetensors:  89% 83.9M/93.9M [00:01<00:00, 106MB/s] \u001b[A\u001b[A\u001b[ADownloading 'latents/layers.8.mlp/52428_78642.safetensors' to 'results/transcoder-llama-131k-mntss/.cache/huggingface/download/latents/layers.8.mlp/D5ZAGWY4JGprrJuJg32OEAI_coI=.a3bd9f367963265f8b0e52cc7bbb8c806eb44c8ef5a63ece34d4ea1cde4266d6.incomplete'\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "78643_104856.safetensors:  79% 73.4M/93.3M [00:01<00:00, 56.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "0_26213.safetensors:  92% 83.9M/91.1M [00:01<00:00, 64.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "26214_52427.safetensors: 100% 93.9M/93.9M [00:01<00:00, 55.7MB/s]\n",
            "Download complete. Moving file to results/transcoder-llama-131k-mntss/latents/layers.7.mlp/26214_52427.safetensors\n",
            "Fetching 98 files:  84% 82/98 [00:20<00:03,  4.83it/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "104857_131071.safetensors:  79% 73.4M/92.5M [00:01<00:00, 66.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "26214_52427.safetensors:  23% 21.0M/89.6M [00:00<00:02, 31.2MB/s]\u001b[ADownloading 'latents/layers.8.mlp/config.json' to 'results/transcoder-llama-131k-mntss/.cache/huggingface/download/latents/layers.8.mlp/8_PA_wEVGiVa2goH2H4KQOQpvVY=.e15d0eb1fb235ccc57b1d72c5aaa2f72eced9fa2.incomplete'\n",
            "52428_78642.safetensors: 100% 93.9M/93.9M [00:01<00:00, 70.2MB/s]\n",
            "Download complete. Moving file to results/transcoder-llama-131k-mntss/latents/layers.7.mlp/52428_78642.safetensors\n",
            "\n",
            "\n",
            "52428_78642.safetensors:   0% 0.00/88.0M [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "config.json: 100% 279/279 [00:00<00:00, 2.51MB/s]\n",
            "Download complete. Moving file to results/transcoder-llama-131k-mntss/latents/layers.8.mlp/config.json\n",
            "Downloading 'latents/layers.9.mlp/0_26213.safetensors' to 'results/transcoder-llama-131k-mntss/.cache/huggingface/download/latents/layers.9.mlp/nzlrvqDo6FcYy0VjcCkWRR0e70U=.f9e95fb284783335debf2e9cd80dbde7c7990a0075c9efc8555a9ec91fefff66.incomplete'\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "0_26213.safetensors: 100% 91.1M/91.1M [00:01<00:00, 65.1MB/s]\n",
            "Download complete. Moving file to results/transcoder-llama-131k-mntss/latents/layers.8.mlp/0_26213.safetensors\n",
            "Downloading 'latents/layers.9.mlp/104857_131071.safetensors' to 'results/transcoder-llama-131k-mntss/.cache/huggingface/download/latents/layers.9.mlp/lu--7ZbzRrZQs-kWIpm2vw7DCuk=.8095437b26e04b66aa12cdc61441a5d68791794751c7c12acf83ed7ba5c5e785.incomplete'\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "78643_104856.safetensors:  90% 83.9M/93.3M [00:01<00:00, 54.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "52428_78642.safetensors:  12% 10.5M/88.0M [00:00<00:00, 81.1MB/s]\u001b[A\u001b[ADownloading 'latents/layers.9.mlp/26214_52427.safetensors' to 'results/transcoder-llama-131k-mntss/.cache/huggingface/download/latents/layers.9.mlp/DfI343hiqeb5QZh_dzGOa9U1tOI=.568dc9b6f1b2aaeef36c3f4eef99468202b61e9e02db38b437adb090f0f8d14b.incomplete'\n",
            "\n",
            "78643_104856.safetensors: 100% 93.3M/93.3M [00:01<00:00, 63.2MB/s]\n",
            "Download complete. Moving file to results/transcoder-llama-131k-mntss/latents/layers.7.mlp/78643_104856.safetensors\n",
            "Fetching 98 files:  86% 84/98 [00:21<00:02,  5.43it/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "104857_131071.safetensors:  91% 83.9M/92.5M [00:01<00:00, 59.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ADownloading 'latents/layers.9.mlp/52428_78642.safetensors' to 'results/transcoder-llama-131k-mntss/.cache/huggingface/download/latents/layers.9.mlp/D5ZAGWY4JGprrJuJg32OEAI_coI=.798a85526270c5edb5d50ba3907cfeb841c403a8b45e3f84a263bc14d74f46d5.incomplete'\n",
            "\n",
            "\n",
            "\n",
            "104857_131071.safetensors:   0% 0.00/106M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "104857_131071.safetensors: 100% 92.5M/92.5M [00:01<00:00, 60.7MB/s]\n",
            "Download complete. Moving file to results/transcoder-llama-131k-mntss/latents/layers.8.mlp/104857_131071.safetensors\n",
            "Fetching 98 files:  89% 87/98 [00:21<00:01,  7.39it/s]\n",
            "26214_52427.safetensors:  58% 52.4M/89.6M [00:00<00:00, 57.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "26214_52427.safetensors:   0% 0.00/104M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[ADownloading 'latents/layers.9.mlp/78643_104856.safetensors' to 'results/transcoder-llama-131k-mntss/.cache/huggingface/download/latents/layers.9.mlp/Z1qsMB7fH8Q67YIj0ULmBJBlW_E=.67b299692963cea4ac08d5cff315a3ac16a696bc49b09db85a41f6dd1cf8d22f.incomplete'\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "0_26213.safetensors:   0% 0.00/107M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "52428_78642.safetensors:  24% 21.0M/88.0M [00:00<00:01, 40.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "104857_131071.safetensors:  20% 21.0M/106M [00:00<00:00, 95.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "52428_78642.safetensors:   0% 0.00/107M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "0_26213.safetensors:  10% 10.5M/107M [00:00<00:01, 64.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "78643_104856.safetensors:   0% 0.00/104M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "26214_52427.safetensors:  20% 21.0M/104M [00:00<00:01, 69.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "104857_131071.safetensors:  30% 31.5M/106M [00:00<00:00, 81.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "52428_78642.safetensors:  10% 10.5M/107M [00:00<00:01, 69.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "26214_52427.safetensors:  82% 73.4M/89.6M [00:01<00:00, 56.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "78643_104856.safetensors:  10% 10.5M/104M [00:00<00:01, 76.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "26214_52427.safetensors:  30% 31.5M/104M [00:00<00:01, 68.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "0_26213.safetensors:  20% 21.0M/107M [00:00<00:01, 47.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "52428_78642.safetensors:  20% 21.0M/107M [00:00<00:01, 65.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "104857_131071.safetensors:  40% 41.9M/106M [00:00<00:01, 57.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "78643_104856.safetensors:  30% 31.5M/104M [00:00<00:00, 104MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "0_26213.safetensors:  29% 31.5M/107M [00:00<00:01, 62.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "26214_52427.safetensors:  40% 41.9M/104M [00:00<00:00, 68.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "52428_78642.safetensors:  29% 31.5M/107M [00:00<00:00, 75.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ADownloading 'latents/layers.8.mlp/78643_104856.safetensors' to 'results/transcoder-llama-131k-mntss/.cache/huggingface/download/latents/layers.8.mlp/Z1qsMB7fH8Q67YIj0ULmBJBlW_E=.68eaebace6115488ec1e0779a78bb7ee018e388b1e625b70861d7f6c4791d8a5.incomplete'\n",
            "\n",
            "26214_52427.safetensors:  94% 83.9M/89.6M [00:01<00:00, 44.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "0_26213.safetensors:  39% 41.9M/107M [00:00<00:01, 61.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "52428_78642.safetensors:  36% 31.5M/88.0M [00:01<00:02, 23.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "78643_104856.safetensors:  40% 41.9M/104M [00:00<00:00, 76.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "26214_52427.safetensors: 100% 89.6M/89.6M [00:01<00:00, 48.4MB/s]\n",
            "Download complete. Moving file to results/transcoder-llama-131k-mntss/latents/layers.8.mlp/26214_52427.safetensors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "26214_52427.safetensors:  51% 52.4M/104M [00:00<00:00, 58.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "104857_131071.safetensors:  50% 52.4M/106M [00:00<00:01, 48.9MB/s]\u001b[A\u001b[A\u001b[ADownloading 'latents/layers.9.mlp/config.json' to 'results/transcoder-llama-131k-mntss/.cache/huggingface/download/latents/layers.9.mlp/8_PA_wEVGiVa2goH2H4KQOQpvVY=.e15d0eb1fb235ccc57b1d72c5aaa2f72eced9fa2.incomplete'\n",
            "\n",
            "config.json: 100% 279/279 [00:00<00:00, 2.43MB/s]\n",
            "Download complete. Moving file to results/transcoder-llama-131k-mntss/latents/layers.9.mlp/config.json\n",
            "\n",
            "78643_104856.safetensors:   0% 0.00/90.2M [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "52428_78642.safetensors:  48% 41.9M/88.0M [00:01<00:01, 30.3MB/s]\u001b[A\u001b[ADownloading 'run_config.json' to 'results/transcoder-llama-131k-mntss/.cache/huggingface/download/XUOp3pisl3GOCgBIcNTOnMI2xY4=.f650a3f7db363d6a11e9d8bbe217ff888ae1145d.incomplete'\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "run_config.json: 100% 2.00k/2.00k [00:00<00:00, 21.6MB/s]\n",
            "Download complete. Moving file to results/transcoder-llama-131k-mntss/run_config.json\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "0_26213.safetensors:  49% 52.4M/107M [00:01<00:01, 47.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "52428_78642.safetensors:  49% 52.4M/107M [00:00<00:01, 51.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "78643_104856.safetensors:  12% 10.5M/90.2M [00:00<00:01, 58.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "26214_52427.safetensors:  71% 73.4M/104M [00:01<00:00, 64.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "78643_104856.safetensors:  50% 52.4M/104M [00:00<00:01, 49.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "0_26213.safetensors:  59% 62.9M/107M [00:01<00:00, 56.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "78643_104856.safetensors:  23% 21.0M/90.2M [00:00<00:01, 67.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "104857_131071.safetensors:  69% 73.4M/106M [00:01<00:00, 50.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "52428_78642.safetensors:  60% 52.4M/88.0M [00:01<00:01, 31.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "26214_52427.safetensors:  81% 83.9M/104M [00:01<00:00, 58.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "0_26213.safetensors:  69% 73.4M/107M [00:01<00:00, 58.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "78643_104856.safetensors:  35% 31.5M/90.2M [00:00<00:00, 72.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "104857_131071.safetensors:  79% 83.9M/106M [00:01<00:00, 55.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "78643_104856.safetensors:  71% 73.4M/104M [00:01<00:00, 58.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "26214_52427.safetensors:  91% 94.4M/104M [00:01<00:00, 64.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "104857_131071.safetensors:  89% 94.4M/106M [00:01<00:00, 61.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "0_26213.safetensors:  78% 83.9M/107M [00:01<00:00, 57.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "52428_78642.safetensors:  69% 73.4M/107M [00:01<00:00, 47.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "52428_78642.safetensors:  83% 73.4M/88.0M [00:01<00:00, 43.5MB/s]\u001b[A\u001b[A\n",
            "78643_104856.safetensors:  46% 41.9M/90.2M [00:00<00:00, 55.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "0_26213.safetensors:  88% 94.4M/107M [00:01<00:00, 63.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "78643_104856.safetensors:  81% 83.9M/104M [00:01<00:00, 52.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "26214_52427.safetensors: 100% 104M/104M [00:01<00:00, 57.2MB/s]\n",
            "Download complete. Moving file to results/transcoder-llama-131k-mntss/latents/layers.9.mlp/26214_52427.safetensors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "52428_78642.safetensors:  78% 83.9M/107M [00:01<00:00, 45.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "78643_104856.safetensors:  58% 52.4M/90.2M [00:00<00:00, 53.0MB/s]\u001b[A\n",
            "\n",
            "52428_78642.safetensors:  95% 83.9M/88.0M [00:02<00:00, 39.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "0_26213.safetensors: 100% 107M/107M [00:01<00:00, 57.3MB/s]\n",
            "Download complete. Moving file to results/transcoder-llama-131k-mntss/latents/layers.9.mlp/0_26213.safetensors\n",
            "\n",
            "\n",
            "\n",
            "52428_78642.safetensors: 100% 88.0M/88.0M [00:02<00:00, 36.4MB/s]\n",
            "Download complete. Moving file to results/transcoder-llama-131k-mntss/latents/layers.8.mlp/52428_78642.safetensors\n",
            "104857_131071.safetensors: 100% 106M/106M [00:02<00:00, 49.7MB/s]\n",
            "Download complete. Moving file to results/transcoder-llama-131k-mntss/latents/layers.9.mlp/104857_131071.safetensors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "52428_78642.safetensors: 100% 107M/107M [00:01<00:00, 53.6MB/s]\n",
            "Download complete. Moving file to results/transcoder-llama-131k-mntss/latents/layers.9.mlp/52428_78642.safetensors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "78643_104856.safetensors: 100% 104M/104M [00:01<00:00, 52.0MB/s]\n",
            "Download complete. Moving file to results/transcoder-llama-131k-mntss/latents/layers.9.mlp/78643_104856.safetensors\n",
            "\n",
            "78643_104856.safetensors:  81% 73.4M/90.2M [00:01<00:00, 42.9MB/s]\u001b[A\n",
            "78643_104856.safetensors: 100% 90.2M/90.2M [00:01<00:00, 47.7MB/s]\n",
            "Download complete. Moving file to results/transcoder-llama-131k-mntss/latents/layers.8.mlp/78643_104856.safetensors\n",
            "Fetching 98 files: 100% 98/98 [00:24<00:00,  4.05it/s]\n",
            "/content/attribute/results/transcoder-llama-131k-mntss\n"
          ]
        }
      ],
      "source": [
        "#@markdown this flag is necesssary viewing feature visualizations. however, cache files take a while to download and process, so you may want to disable this.\n",
        "download_llama_cache = True  #@param {type:\"boolean\"}\n",
        "if download_llama_cache:\n",
        "    !huggingface-cli download EleutherAI/Llama-3.2-1B-mntss-skip-transcoder-cache-1M --local-dir results/transcoder-llama-131k-mntss\n",
        "download_gemma_cache = False  #@param {type:\"boolean\"}\n",
        "if download_gemma_cache:\n",
        "    !huggingface-cli download EleutherAI/gemmascope-transcoders-sparsify-cache-1m --local-dir results/gemmascope-transcoders-sparsify-1m\n",
        "download_cache = download_llama_cache or download_gemma_cache"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "396ace78a4d349119c0be34e8a16cb82",
            "d47ee015c5864990a6f4ce5aa447341a",
            "012cfeb33df642adbe600a4996319332",
            "1a43cd89356c48f89ce2d24b9cfbc164",
            "dfdc8bb3cacc4d7ea6f96963db6f9049",
            "0102a14c2c95416388e87c681b0f4fab",
            "721589b2ba8649998efb462b3e881201",
            "4ac834802d1940d8b54e9165cb3cd2b7",
            "0389d97bac96409ba2334fb653b6c40f",
            "74c094602de149b0873dad499a7a843d",
            "137a4d75b5624e76b88536ddbc977988",
            "c8b9e07926f64721b2d5e3c2ea14bf2f",
            "ee1833cbb24b4d61a0cd1d2bfdcaf9a0",
            "7141cb9e6edd45669e429c1d9e88b4bf",
            "b7f981986b9942fc93c7496ff56eeb20",
            "91afd8de587c4e6583d06ecac36feea9",
            "94113f287eab4116a1e769071c6f3c72",
            "59483c64eb5941aba95d39b70216af20",
            "3a2676e1969f446696b22eee47556083",
            "8c2ebcf302c4463db66404bf408cc3a5",
            "717fd223f80547c9819768fc39e97380",
            "6f6d001f779f4e71879ff828b90a2cf7",
            "ea68b36948044fda93e34819e8bf7fe3",
            "aef827beb7504708b3d73c2c40e05257",
            "ec30460532114a278511aad335930da2",
            "549f9e05dbf34f4699b067f0fe3f2093",
            "2293eb4fab564adbbab768f0f2d92abd",
            "7001546681f04d19805864f47e29feae",
            "88ee8b96da8d48dca8f8ab013abc2996",
            "f7741a104a814a1b99f8f75f39b73e7d",
            "2d412f8be70d49ef933125f8d9bbd3df",
            "2761a2936cea46e69925ac55540deeda",
            "12f34a8a53254fdcafd6c8f86f14fbdb",
            "ad1848b50b1b4ac4beeac90e689042d8",
            "fd11d6285cf84ce38e61719adbad95dc",
            "2273f7d44d994b57bd4b5019453941c2",
            "2b193ed8953d4abeb5adee7aa8a07e18",
            "dfd8302127af457c8eef51be3d97fd7d",
            "0818671ff2f4483fa89112b8a897edba",
            "a16e0fda54da42f6ab3c4d930765a8be",
            "259fb420875d471faf4746c5d57aae3e",
            "2477e756b3fc4eb2ba425c8b13af3e35",
            "949577afc3cf44f6bc62b2cbe65b5b01",
            "618db6143ee142699e646380539d00f5",
            "90c238c080f94142956efac617c3387e",
            "8fea3f3ec99f4cfbb063fa6a495ae909",
            "6d4d5223d0504af180eb5752deee5c23",
            "414233397b6f47d9b0cc4ff092a5bdb3",
            "28e73d024c37439a82e0e19dc0bf6cdc",
            "bc0555c1e2fb44dba77c8e1223f7695b",
            "11c959768da147938a9c2f3920b964f8",
            "561e0533016e4e0ca528b29b8084af90",
            "7f93abad431b4818a3b1bdc07349026b",
            "7ac29643164645c6828f11182536e583",
            "1502165a0f40409bbc3efdb9d68ca2ff",
            "22ddc5cbda864c87b73d124442211828",
            "74322ef1c78f4e7fa0935f5ec89fb26d",
            "dd9b755a75934fab93a2429797d8319d",
            "4fc35a9ca62041cb9ab62d12d3b3e489",
            "346714ffa0c146ae8bec4e6a8e481d56",
            "40f3e8a018c4439885c9acc639f544d3",
            "1a9ddedfe1574bfe902fedd36d88c458",
            "005811c29d80441682acd0b41334d4f3",
            "e4c3cca56f5a4c4abca2bf3f00198f80",
            "03fc5bf0694f4da9b226a86e9981508a",
            "3b882f31b1084b87b2bb223d9a863384",
            "8cdbcfc5f12e4ea0a9652742c5bf4919",
            "31ab43420e55409a88d80bfc052cb797",
            "a1ad3b9777704962947f9189dbed976f",
            "cb88149ca6c44433868d48f673a3aab3",
            "f43e893304b84fe592d056f62244cf1c",
            "8259034b887248af90300b3e873ae2eb",
            "16301d26d736409889b4019a926fc060",
            "fa5b89cc72b140b5a7b0a8789fe690e1",
            "903c1532051c47a6b63ad7ec91f1d5d6",
            "b884f03d0b7e457d8582efbf4ca95d34",
            "7697b6c607884cf085d7c09064907a06",
            "05a94678bb6c4715aa97bcb16776fb36",
            "5fd9e0925e624b9b9287ee1d751ed7c8",
            "8fb5f9b2514f4af5ae57ef40c9b8a528",
            "4b58efaabeb647348d906adc05772140",
            "69935e09a8e842e2aa8677d97a36b8f2",
            "77e62fc02d374f1aaa1e3b8dee6ae023",
            "f9a1e6047c9a46ba9a6e854735081a08",
            "b0dbc5697ee44c4780e5cf44ce51a732",
            "3c4a22e189774ae8899dd542f7ea74ba",
            "f6c731d35f81477bab05c2dce4ce89a2",
            "0b4b28d63fcb488bbe28a94e76d1e4aa"
          ]
        },
        "id": "wdd76XU5ZkCS",
        "outputId": "dfafa3fa-a194-4246-e447-c9015ce369bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Triton disabled, using eager implementation of sparse decoder.\n",
            "['attribution-graphs-frontend', 'attribution-graphs-frontend/features/transcoder-llama-131k-mntss', 'attribution-graphs-frontend/features/gemmascope-transcoders-sparsify', 'attribution-graphs-frontend/features/smollm-v1']\n",
            "Caching examples at: '/content/attribute/.gradio/cached_examples/23'\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://8c00ed3685ed34e96c.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://8c00ed3685ed34e96c.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m2025-06-16 20:26:11.540\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mattribute.caching\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m78\u001b[0m - \u001b[1mLoading model meta-llama/Llama-3.2-1B on device cuda\u001b[0m\n",
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_http.py\", line 409, in hf_raise_for_status\n",
            "    response.raise_for_status()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/requests/models.py\", line 1024, in raise_for_status\n",
            "    raise HTTPError(http_error_msg, response=self)\n",
            "requests.exceptions.HTTPError: 403 Client Error: Forbidden for url: https://huggingface.co/meta-llama/Llama-3.2-1B/resolve/main/config.json\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/hub.py\", line 470, in cached_files\n",
            "    hf_hub_download(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_validators.py\", line 114, in _inner_fn\n",
            "    return fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\", line 1008, in hf_hub_download\n",
            "    return _hf_hub_download_to_cache_dir(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\", line 1115, in _hf_hub_download_to_cache_dir\n",
            "    _raise_on_head_call_error(head_call_error, force_download, local_files_only)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\", line 1645, in _raise_on_head_call_error\n",
            "    raise head_call_error\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\", line 1533, in _get_metadata_or_catch_error\n",
            "    metadata = get_hf_file_metadata(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_validators.py\", line 114, in _inner_fn\n",
            "    return fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\", line 1450, in get_hf_file_metadata\n",
            "    r = _request_wrapper(\n",
            "        ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\", line 286, in _request_wrapper\n",
            "    response = _request_wrapper(\n",
            "               ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\", line 310, in _request_wrapper\n",
            "    hf_raise_for_status(response)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_http.py\", line 426, in hf_raise_for_status\n",
            "    raise _format(GatedRepoError, message, response) from e\n",
            "huggingface_hub.errors.GatedRepoError: 403 Client Error. (Request ID: Root=1-68507de3-3779d59b143dd0b901521108;f33c6a81-951a-4649-a409-267f2e793349)\n",
            "\n",
            "Cannot access gated repo for url https://huggingface.co/meta-llama/Llama-3.2-1B/resolve/main/config.json.\n",
            "Access to model meta-llama/Llama-3.2-1B is restricted and you are not in the authorized list. Visit https://huggingface.co/meta-llama/Llama-3.2-1B to ask for access.\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/queueing.py\", line 625, in process_events\n",
            "    response = await route_utils.call_process_api(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/route_utils.py\", line 322, in call_process_api\n",
            "    output = await app.get_blocks().process_api(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/blocks.py\", line 2220, in process_api\n",
            "    result = await self.call_function(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/blocks.py\", line 1731, in call_function\n",
            "    prediction = await anyio.to_thread.run_sync(  # type: ignore\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/anyio/to_thread.py\", line 56, in run_sync\n",
            "    return await get_async_backend().run_sync_in_worker_thread(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/anyio/_backends/_asyncio.py\", line 2470, in run_sync_in_worker_thread\n",
            "    return await future\n",
            "           ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/anyio/_backends/_asyncio.py\", line 967, in run\n",
            "    result = context.run(func, *args)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/utils.py\", line 894, in wrapper\n",
            "    response = f(*args, **kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/attribute/serve.py\", line 99, in generate\n",
            "    model_cache[model_name] = TranscodedModel(\n",
            "                              ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/attribute/attribute/caching.py\", line 84, in __init__\n",
            "    model = AutoModelForCausalLM.from_pretrained(\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/models/auto/auto_factory.py\", line 531, in from_pretrained\n",
            "    config, kwargs = AutoConfig.from_pretrained(\n",
            "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/models/auto/configuration_auto.py\", line 1153, in from_pretrained\n",
            "    config_dict, unused_kwargs = PretrainedConfig.get_config_dict(pretrained_model_name_or_path, **kwargs)\n",
            "                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/configuration_utils.py\", line 595, in get_config_dict\n",
            "    config_dict, kwargs = cls._get_config_dict(pretrained_model_name_or_path, **kwargs)\n",
            "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/configuration_utils.py\", line 654, in _get_config_dict\n",
            "    resolved_config_file = cached_file(\n",
            "                           ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/hub.py\", line 312, in cached_file\n",
            "    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/hub.py\", line 533, in cached_files\n",
            "    raise OSError(\n",
            "OSError: You are trying to access a gated repo.\n",
            "Make sure to have access to it at https://huggingface.co/meta-llama/Llama-3.2-1B.\n",
            "403 Client Error. (Request ID: Root=1-68507de3-3779d59b143dd0b901521108;f33c6a81-951a-4649-a409-267f2e793349)\n",
            "\n",
            "Cannot access gated repo for url https://huggingface.co/meta-llama/Llama-3.2-1B/resolve/main/config.json.\n",
            "Access to model meta-llama/Llama-3.2-1B is restricted and you are not in the authorized list. Visit https://huggingface.co/meta-llama/Llama-3.2-1B to ask for access.\n",
            "\u001b[32m2025-06-16 20:26:14.078\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mattribute.caching\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m78\u001b[0m - \u001b[1mLoading model meta-llama/Llama-3.2-1B on device cuda\u001b[0m\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_http.py\", line 409, in hf_raise_for_status\n",
            "    response.raise_for_status()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/requests/models.py\", line 1024, in raise_for_status\n",
            "    raise HTTPError(http_error_msg, response=self)\n",
            "requests.exceptions.HTTPError: 403 Client Error: Forbidden for url: https://huggingface.co/meta-llama/Llama-3.2-1B/resolve/main/config.json\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/hub.py\", line 470, in cached_files\n",
            "    hf_hub_download(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_validators.py\", line 114, in _inner_fn\n",
            "    return fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\", line 1008, in hf_hub_download\n",
            "    return _hf_hub_download_to_cache_dir(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\", line 1115, in _hf_hub_download_to_cache_dir\n",
            "    _raise_on_head_call_error(head_call_error, force_download, local_files_only)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\", line 1645, in _raise_on_head_call_error\n",
            "    raise head_call_error\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\", line 1533, in _get_metadata_or_catch_error\n",
            "    metadata = get_hf_file_metadata(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_validators.py\", line 114, in _inner_fn\n",
            "    return fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\", line 1450, in get_hf_file_metadata\n",
            "    r = _request_wrapper(\n",
            "        ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\", line 286, in _request_wrapper\n",
            "    response = _request_wrapper(\n",
            "               ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\", line 310, in _request_wrapper\n",
            "    hf_raise_for_status(response)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_http.py\", line 426, in hf_raise_for_status\n",
            "    raise _format(GatedRepoError, message, response) from e\n",
            "huggingface_hub.errors.GatedRepoError: 403 Client Error. (Request ID: Root=1-68507de6-5fc0cee71aa2ee2415aeaf2e;5730e419-c4ff-4f55-baba-9a21dbd95487)\n",
            "\n",
            "Cannot access gated repo for url https://huggingface.co/meta-llama/Llama-3.2-1B/resolve/main/config.json.\n",
            "Access to model meta-llama/Llama-3.2-1B is restricted and you are not in the authorized list. Visit https://huggingface.co/meta-llama/Llama-3.2-1B to ask for access.\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/queueing.py\", line 625, in process_events\n",
            "    response = await route_utils.call_process_api(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/route_utils.py\", line 322, in call_process_api\n",
            "    output = await app.get_blocks().process_api(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/blocks.py\", line 2220, in process_api\n",
            "    result = await self.call_function(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/blocks.py\", line 1731, in call_function\n",
            "    prediction = await anyio.to_thread.run_sync(  # type: ignore\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/anyio/to_thread.py\", line 56, in run_sync\n",
            "    return await get_async_backend().run_sync_in_worker_thread(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/anyio/_backends/_asyncio.py\", line 2470, in run_sync_in_worker_thread\n",
            "    return await future\n",
            "           ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/anyio/_backends/_asyncio.py\", line 967, in run\n",
            "    result = context.run(func, *args)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/utils.py\", line 894, in wrapper\n",
            "    response = f(*args, **kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/attribute/serve.py\", line 99, in generate\n",
            "    model_cache[model_name] = TranscodedModel(\n",
            "                              ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/attribute/attribute/caching.py\", line 84, in __init__\n",
            "    model = AutoModelForCausalLM.from_pretrained(\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/models/auto/auto_factory.py\", line 531, in from_pretrained\n",
            "    config, kwargs = AutoConfig.from_pretrained(\n",
            "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/models/auto/configuration_auto.py\", line 1153, in from_pretrained\n",
            "    config_dict, unused_kwargs = PretrainedConfig.get_config_dict(pretrained_model_name_or_path, **kwargs)\n",
            "                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/configuration_utils.py\", line 595, in get_config_dict\n",
            "    config_dict, kwargs = cls._get_config_dict(pretrained_model_name_or_path, **kwargs)\n",
            "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/configuration_utils.py\", line 654, in _get_config_dict\n",
            "    resolved_config_file = cached_file(\n",
            "                           ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/hub.py\", line 312, in cached_file\n",
            "    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/hub.py\", line 533, in cached_files\n",
            "    raise OSError(\n",
            "OSError: You are trying to access a gated repo.\n",
            "Make sure to have access to it at https://huggingface.co/meta-llama/Llama-3.2-1B.\n",
            "403 Client Error. (Request ID: Root=1-68507de6-5fc0cee71aa2ee2415aeaf2e;5730e419-c4ff-4f55-baba-9a21dbd95487)\n",
            "\n",
            "Cannot access gated repo for url https://huggingface.co/meta-llama/Llama-3.2-1B/resolve/main/config.json.\n",
            "Access to model meta-llama/Llama-3.2-1B is restricted and you are not in the authorized list. Visit https://huggingface.co/meta-llama/Llama-3.2-1B to ask for access.\n",
            "\u001b[32m2025-06-16 20:26:15.346\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mattribute.caching\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m78\u001b[0m - \u001b[1mLoading model meta-llama/Llama-3.2-1B on device cuda\u001b[0m\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_http.py\", line 409, in hf_raise_for_status\n",
            "    response.raise_for_status()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/requests/models.py\", line 1024, in raise_for_status\n",
            "    raise HTTPError(http_error_msg, response=self)\n",
            "requests.exceptions.HTTPError: 403 Client Error: Forbidden for url: https://huggingface.co/meta-llama/Llama-3.2-1B/resolve/main/config.json\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/hub.py\", line 470, in cached_files\n",
            "    hf_hub_download(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_validators.py\", line 114, in _inner_fn\n",
            "    return fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\", line 1008, in hf_hub_download\n",
            "    return _hf_hub_download_to_cache_dir(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\", line 1115, in _hf_hub_download_to_cache_dir\n",
            "    _raise_on_head_call_error(head_call_error, force_download, local_files_only)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\", line 1645, in _raise_on_head_call_error\n",
            "    raise head_call_error\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\", line 1533, in _get_metadata_or_catch_error\n",
            "    metadata = get_hf_file_metadata(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_validators.py\", line 114, in _inner_fn\n",
            "    return fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\", line 1450, in get_hf_file_metadata\n",
            "    r = _request_wrapper(\n",
            "        ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\", line 286, in _request_wrapper\n",
            "    response = _request_wrapper(\n",
            "               ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\", line 310, in _request_wrapper\n",
            "    hf_raise_for_status(response)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_http.py\", line 426, in hf_raise_for_status\n",
            "    raise _format(GatedRepoError, message, response) from e\n",
            "huggingface_hub.errors.GatedRepoError: 403 Client Error. (Request ID: Root=1-68507de7-61770e86176f3ba5543bedf0;a7259d92-3a8d-41de-96a8-540875868706)\n",
            "\n",
            "Cannot access gated repo for url https://huggingface.co/meta-llama/Llama-3.2-1B/resolve/main/config.json.\n",
            "Access to model meta-llama/Llama-3.2-1B is restricted and you are not in the authorized list. Visit https://huggingface.co/meta-llama/Llama-3.2-1B to ask for access.\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/queueing.py\", line 625, in process_events\n",
            "    response = await route_utils.call_process_api(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/route_utils.py\", line 322, in call_process_api\n",
            "    output = await app.get_blocks().process_api(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/blocks.py\", line 2220, in process_api\n",
            "    result = await self.call_function(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/blocks.py\", line 1731, in call_function\n",
            "    prediction = await anyio.to_thread.run_sync(  # type: ignore\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/anyio/to_thread.py\", line 56, in run_sync\n",
            "    return await get_async_backend().run_sync_in_worker_thread(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/anyio/_backends/_asyncio.py\", line 2470, in run_sync_in_worker_thread\n",
            "    return await future\n",
            "           ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/anyio/_backends/_asyncio.py\", line 967, in run\n",
            "    result = context.run(func, *args)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/utils.py\", line 894, in wrapper\n",
            "    response = f(*args, **kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/attribute/serve.py\", line 99, in generate\n",
            "    model_cache[model_name] = TranscodedModel(\n",
            "                              ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/attribute/attribute/caching.py\", line 84, in __init__\n",
            "    model = AutoModelForCausalLM.from_pretrained(\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/models/auto/auto_factory.py\", line 531, in from_pretrained\n",
            "    config, kwargs = AutoConfig.from_pretrained(\n",
            "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/models/auto/configuration_auto.py\", line 1153, in from_pretrained\n",
            "    config_dict, unused_kwargs = PretrainedConfig.get_config_dict(pretrained_model_name_or_path, **kwargs)\n",
            "                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/configuration_utils.py\", line 595, in get_config_dict\n",
            "    config_dict, kwargs = cls._get_config_dict(pretrained_model_name_or_path, **kwargs)\n",
            "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/configuration_utils.py\", line 654, in _get_config_dict\n",
            "    resolved_config_file = cached_file(\n",
            "                           ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/hub.py\", line 312, in cached_file\n",
            "    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/hub.py\", line 533, in cached_files\n",
            "    raise OSError(\n",
            "OSError: You are trying to access a gated repo.\n",
            "Make sure to have access to it at https://huggingface.co/meta-llama/Llama-3.2-1B.\n",
            "403 Client Error. (Request ID: Root=1-68507de7-61770e86176f3ba5543bedf0;a7259d92-3a8d-41de-96a8-540875868706)\n",
            "\n",
            "Cannot access gated repo for url https://huggingface.co/meta-llama/Llama-3.2-1B/resolve/main/config.json.\n",
            "Access to model meta-llama/Llama-3.2-1B is restricted and you are not in the authorized list. Visit https://huggingface.co/meta-llama/Llama-3.2-1B to ask for access.\n",
            "\u001b[32m2025-06-16 20:26:16.411\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mattribute.caching\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m78\u001b[0m - \u001b[1mLoading model meta-llama/Llama-3.2-1B on device cuda\u001b[0m\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_http.py\", line 409, in hf_raise_for_status\n",
            "    response.raise_for_status()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/requests/models.py\", line 1024, in raise_for_status\n",
            "    raise HTTPError(http_error_msg, response=self)\n",
            "requests.exceptions.HTTPError: 403 Client Error: Forbidden for url: https://huggingface.co/meta-llama/Llama-3.2-1B/resolve/main/config.json\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/hub.py\", line 470, in cached_files\n",
            "    hf_hub_download(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_validators.py\", line 114, in _inner_fn\n",
            "    return fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\", line 1008, in hf_hub_download\n",
            "    return _hf_hub_download_to_cache_dir(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\", line 1115, in _hf_hub_download_to_cache_dir\n",
            "    _raise_on_head_call_error(head_call_error, force_download, local_files_only)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\", line 1645, in _raise_on_head_call_error\n",
            "    raise head_call_error\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\", line 1533, in _get_metadata_or_catch_error\n",
            "    metadata = get_hf_file_metadata(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_validators.py\", line 114, in _inner_fn\n",
            "    return fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\", line 1450, in get_hf_file_metadata\n",
            "    r = _request_wrapper(\n",
            "        ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\", line 286, in _request_wrapper\n",
            "    response = _request_wrapper(\n",
            "               ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\", line 310, in _request_wrapper\n",
            "    hf_raise_for_status(response)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_http.py\", line 426, in hf_raise_for_status\n",
            "    raise _format(GatedRepoError, message, response) from e\n",
            "huggingface_hub.errors.GatedRepoError: 403 Client Error. (Request ID: Root=1-68507de8-7eecf8c4489213bb2c6869d1;18f9f532-ca31-4eb4-ab21-74d8dce0c5a9)\n",
            "\n",
            "Cannot access gated repo for url https://huggingface.co/meta-llama/Llama-3.2-1B/resolve/main/config.json.\n",
            "Access to model meta-llama/Llama-3.2-1B is restricted and you are not in the authorized list. Visit https://huggingface.co/meta-llama/Llama-3.2-1B to ask for access.\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/queueing.py\", line 625, in process_events\n",
            "    response = await route_utils.call_process_api(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/route_utils.py\", line 322, in call_process_api\n",
            "    output = await app.get_blocks().process_api(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/blocks.py\", line 2220, in process_api\n",
            "    result = await self.call_function(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/blocks.py\", line 1731, in call_function\n",
            "    prediction = await anyio.to_thread.run_sync(  # type: ignore\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/anyio/to_thread.py\", line 56, in run_sync\n",
            "    return await get_async_backend().run_sync_in_worker_thread(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/anyio/_backends/_asyncio.py\", line 2470, in run_sync_in_worker_thread\n",
            "    return await future\n",
            "           ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/anyio/_backends/_asyncio.py\", line 967, in run\n",
            "    result = context.run(func, *args)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/utils.py\", line 894, in wrapper\n",
            "    response = f(*args, **kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/attribute/serve.py\", line 99, in generate\n",
            "    model_cache[model_name] = TranscodedModel(\n",
            "                              ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/attribute/attribute/caching.py\", line 84, in __init__\n",
            "    model = AutoModelForCausalLM.from_pretrained(\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/models/auto/auto_factory.py\", line 531, in from_pretrained\n",
            "    config, kwargs = AutoConfig.from_pretrained(\n",
            "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/models/auto/configuration_auto.py\", line 1153, in from_pretrained\n",
            "    config_dict, unused_kwargs = PretrainedConfig.get_config_dict(pretrained_model_name_or_path, **kwargs)\n",
            "                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/configuration_utils.py\", line 595, in get_config_dict\n",
            "    config_dict, kwargs = cls._get_config_dict(pretrained_model_name_or_path, **kwargs)\n",
            "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/configuration_utils.py\", line 654, in _get_config_dict\n",
            "    resolved_config_file = cached_file(\n",
            "                           ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/hub.py\", line 312, in cached_file\n",
            "    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/hub.py\", line 533, in cached_files\n",
            "    raise OSError(\n",
            "OSError: You are trying to access a gated repo.\n",
            "Make sure to have access to it at https://huggingface.co/meta-llama/Llama-3.2-1B.\n",
            "403 Client Error. (Request ID: Root=1-68507de8-7eecf8c4489213bb2c6869d1;18f9f532-ca31-4eb4-ab21-74d8dce0c5a9)\n",
            "\n",
            "Cannot access gated repo for url https://huggingface.co/meta-llama/Llama-3.2-1B/resolve/main/config.json.\n",
            "Access to model meta-llama/Llama-3.2-1B is restricted and you are not in the authorized list. Visit https://huggingface.co/meta-llama/Llama-3.2-1B to ask for access.\n",
            "\u001b[32m2025-06-16 20:26:17.373\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mattribute.caching\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m78\u001b[0m - \u001b[1mLoading model meta-llama/Llama-3.2-1B on device cuda\u001b[0m\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_http.py\", line 409, in hf_raise_for_status\n",
            "    response.raise_for_status()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/requests/models.py\", line 1024, in raise_for_status\n",
            "    raise HTTPError(http_error_msg, response=self)\n",
            "requests.exceptions.HTTPError: 403 Client Error: Forbidden for url: https://huggingface.co/meta-llama/Llama-3.2-1B/resolve/main/config.json\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/hub.py\", line 470, in cached_files\n",
            "    hf_hub_download(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_validators.py\", line 114, in _inner_fn\n",
            "    return fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\", line 1008, in hf_hub_download\n",
            "    return _hf_hub_download_to_cache_dir(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\", line 1115, in _hf_hub_download_to_cache_dir\n",
            "    _raise_on_head_call_error(head_call_error, force_download, local_files_only)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\", line 1645, in _raise_on_head_call_error\n",
            "    raise head_call_error\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\", line 1533, in _get_metadata_or_catch_error\n",
            "    metadata = get_hf_file_metadata(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_validators.py\", line 114, in _inner_fn\n",
            "    return fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\", line 1450, in get_hf_file_metadata\n",
            "    r = _request_wrapper(\n",
            "        ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\", line 286, in _request_wrapper\n",
            "    response = _request_wrapper(\n",
            "               ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\", line 310, in _request_wrapper\n",
            "    hf_raise_for_status(response)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_http.py\", line 426, in hf_raise_for_status\n",
            "    raise _format(GatedRepoError, message, response) from e\n",
            "huggingface_hub.errors.GatedRepoError: 403 Client Error. (Request ID: Root=1-68507de9-2c60a806786f3584600925eb;4788ac43-4c50-4fe1-8f83-dc0967f5821e)\n",
            "\n",
            "Cannot access gated repo for url https://huggingface.co/meta-llama/Llama-3.2-1B/resolve/main/config.json.\n",
            "Access to model meta-llama/Llama-3.2-1B is restricted and you are not in the authorized list. Visit https://huggingface.co/meta-llama/Llama-3.2-1B to ask for access.\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/queueing.py\", line 625, in process_events\n",
            "    response = await route_utils.call_process_api(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/route_utils.py\", line 322, in call_process_api\n",
            "    output = await app.get_blocks().process_api(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/blocks.py\", line 2220, in process_api\n",
            "    result = await self.call_function(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/blocks.py\", line 1731, in call_function\n",
            "    prediction = await anyio.to_thread.run_sync(  # type: ignore\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/anyio/to_thread.py\", line 56, in run_sync\n",
            "    return await get_async_backend().run_sync_in_worker_thread(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/anyio/_backends/_asyncio.py\", line 2470, in run_sync_in_worker_thread\n",
            "    return await future\n",
            "           ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/anyio/_backends/_asyncio.py\", line 967, in run\n",
            "    result = context.run(func, *args)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/utils.py\", line 894, in wrapper\n",
            "    response = f(*args, **kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/attribute/serve.py\", line 99, in generate\n",
            "    model_cache[model_name] = TranscodedModel(\n",
            "                              ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/attribute/attribute/caching.py\", line 84, in __init__\n",
            "    model = AutoModelForCausalLM.from_pretrained(\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/models/auto/auto_factory.py\", line 531, in from_pretrained\n",
            "    config, kwargs = AutoConfig.from_pretrained(\n",
            "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/models/auto/configuration_auto.py\", line 1153, in from_pretrained\n",
            "    config_dict, unused_kwargs = PretrainedConfig.get_config_dict(pretrained_model_name_or_path, **kwargs)\n",
            "                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/configuration_utils.py\", line 595, in get_config_dict\n",
            "    config_dict, kwargs = cls._get_config_dict(pretrained_model_name_or_path, **kwargs)\n",
            "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/configuration_utils.py\", line 654, in _get_config_dict\n",
            "    resolved_config_file = cached_file(\n",
            "                           ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/hub.py\", line 312, in cached_file\n",
            "    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/hub.py\", line 533, in cached_files\n",
            "    raise OSError(\n",
            "OSError: You are trying to access a gated repo.\n",
            "Make sure to have access to it at https://huggingface.co/meta-llama/Llama-3.2-1B.\n",
            "403 Client Error. (Request ID: Root=1-68507de9-2c60a806786f3584600925eb;4788ac43-4c50-4fe1-8f83-dc0967f5821e)\n",
            "\n",
            "Cannot access gated repo for url https://huggingface.co/meta-llama/Llama-3.2-1B/resolve/main/config.json.\n",
            "Access to model meta-llama/Llama-3.2-1B is restricted and you are not in the authorized list. Visit https://huggingface.co/meta-llama/Llama-3.2-1B to ask for access.\n",
            "\u001b[32m2025-06-16 20:26:30.821\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mattribute.caching\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m78\u001b[0m - \u001b[1mLoading model google/gemma-2-2b on device cuda\u001b[0m\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/818 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "396ace78a4d349119c0be34e8a16cb82"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors.index.json:   0%|          | 0.00/24.2k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c8b9e07926f64721b2d5e3c2ea14bf2f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 3 files:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ea68b36948044fda93e34819e8bf7fe3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00001-of-00003.safetensors:   0%|          | 0.00/4.99G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ad1848b50b1b4ac4beeac90e689042d8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00003-of-00003.safetensors:   0%|          | 0.00/481M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "90c238c080f94142956efac617c3387e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00002-of-00003.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "22ddc5cbda864c87b73d124442211828"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8cdbcfc5f12e4ea0a9652742c5bf4919"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/queueing.py\", line 625, in process_events\n",
            "    response = await route_utils.call_process_api(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/route_utils.py\", line 322, in call_process_api\n",
            "    output = await app.get_blocks().process_api(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/blocks.py\", line 2220, in process_api\n",
            "    result = await self.call_function(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/blocks.py\", line 1731, in call_function\n",
            "    prediction = await anyio.to_thread.run_sync(  # type: ignore\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/anyio/to_thread.py\", line 56, in run_sync\n",
            "    return await get_async_backend().run_sync_in_worker_thread(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/anyio/_backends/_asyncio.py\", line 2470, in run_sync_in_worker_thread\n",
            "    return await future\n",
            "           ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/anyio/_backends/_asyncio.py\", line 967, in run\n",
            "    result = context.run(func, *args)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/utils.py\", line 894, in wrapper\n",
            "    response = f(*args, **kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/attribute/serve.py\", line 99, in generate\n",
            "    model_cache[model_name] = TranscodedModel(\n",
            "                              ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/attribute/attribute/caching.py\", line 84, in __init__\n",
            "    model = AutoModelForCausalLM.from_pretrained(\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/models/auto/auto_factory.py\", line 571, in from_pretrained\n",
            "    return model_class.from_pretrained(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\", line 309, in _wrapper\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\", line 4574, in from_pretrained\n",
            "    ) = cls._load_pretrained_model(\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\", line 4991, in _load_pretrained_model\n",
            "    caching_allocator_warmup(model_to_load, expanded_device_map, hf_quantizer)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\", line 6050, in caching_allocator_warmup\n",
            "    index = device.index if device.index is not None else torch.cuda.current_device()\n",
            "                                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py\", line 971, in current_device\n",
            "    _lazy_init()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py\", line 310, in _lazy_init\n",
            "    raise AssertionError(\"Torch not compiled with CUDA enabled\")\n",
            "AssertionError: Torch not compiled with CUDA enabled\n",
            "\u001b[32m2025-06-16 20:27:43.992\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mattribute.caching\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m78\u001b[0m - \u001b[1mLoading model meta-llama/Llama-3.2-1B on device cuda\u001b[0m\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_http.py\", line 409, in hf_raise_for_status\n",
            "    response.raise_for_status()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/requests/models.py\", line 1024, in raise_for_status\n",
            "    raise HTTPError(http_error_msg, response=self)\n",
            "requests.exceptions.HTTPError: 403 Client Error: Forbidden for url: https://huggingface.co/meta-llama/Llama-3.2-1B/resolve/main/config.json\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/hub.py\", line 470, in cached_files\n",
            "    hf_hub_download(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_validators.py\", line 114, in _inner_fn\n",
            "    return fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\", line 1008, in hf_hub_download\n",
            "    return _hf_hub_download_to_cache_dir(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\", line 1115, in _hf_hub_download_to_cache_dir\n",
            "    _raise_on_head_call_error(head_call_error, force_download, local_files_only)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\", line 1645, in _raise_on_head_call_error\n",
            "    raise head_call_error\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\", line 1533, in _get_metadata_or_catch_error\n",
            "    metadata = get_hf_file_metadata(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_validators.py\", line 114, in _inner_fn\n",
            "    return fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\", line 1450, in get_hf_file_metadata\n",
            "    r = _request_wrapper(\n",
            "        ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\", line 286, in _request_wrapper\n",
            "    response = _request_wrapper(\n",
            "               ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\", line 310, in _request_wrapper\n",
            "    hf_raise_for_status(response)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_http.py\", line 426, in hf_raise_for_status\n",
            "    raise _format(GatedRepoError, message, response) from e\n",
            "huggingface_hub.errors.GatedRepoError: 403 Client Error. (Request ID: Root=1-68507e40-6ad9597b7aa1533e46ab655e;63db901e-ea86-4080-8188-c8d717e9c3fe)\n",
            "\n",
            "Cannot access gated repo for url https://huggingface.co/meta-llama/Llama-3.2-1B/resolve/main/config.json.\n",
            "Access to model meta-llama/Llama-3.2-1B is restricted and you are not in the authorized list. Visit https://huggingface.co/meta-llama/Llama-3.2-1B to ask for access.\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/queueing.py\", line 625, in process_events\n",
            "    response = await route_utils.call_process_api(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/route_utils.py\", line 322, in call_process_api\n",
            "    output = await app.get_blocks().process_api(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/blocks.py\", line 2220, in process_api\n",
            "    result = await self.call_function(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/blocks.py\", line 1731, in call_function\n",
            "    prediction = await anyio.to_thread.run_sync(  # type: ignore\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/anyio/to_thread.py\", line 56, in run_sync\n",
            "    return await get_async_backend().run_sync_in_worker_thread(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/anyio/_backends/_asyncio.py\", line 2470, in run_sync_in_worker_thread\n",
            "    return await future\n",
            "           ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/anyio/_backends/_asyncio.py\", line 967, in run\n",
            "    result = context.run(func, *args)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/utils.py\", line 894, in wrapper\n",
            "    response = f(*args, **kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/attribute/serve.py\", line 99, in generate\n",
            "    model_cache[model_name] = TranscodedModel(\n",
            "                              ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/attribute/attribute/caching.py\", line 84, in __init__\n",
            "    model = AutoModelForCausalLM.from_pretrained(\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/models/auto/auto_factory.py\", line 531, in from_pretrained\n",
            "    config, kwargs = AutoConfig.from_pretrained(\n",
            "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/models/auto/configuration_auto.py\", line 1153, in from_pretrained\n",
            "    config_dict, unused_kwargs = PretrainedConfig.get_config_dict(pretrained_model_name_or_path, **kwargs)\n",
            "                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/configuration_utils.py\", line 595, in get_config_dict\n",
            "    config_dict, kwargs = cls._get_config_dict(pretrained_model_name_or_path, **kwargs)\n",
            "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/configuration_utils.py\", line 654, in _get_config_dict\n",
            "    resolved_config_file = cached_file(\n",
            "                           ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/hub.py\", line 312, in cached_file\n",
            "    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/hub.py\", line 533, in cached_files\n",
            "    raise OSError(\n",
            "OSError: You are trying to access a gated repo.\n",
            "Make sure to have access to it at https://huggingface.co/meta-llama/Llama-3.2-1B.\n",
            "403 Client Error. (Request ID: Root=1-68507e40-6ad9597b7aa1533e46ab655e;63db901e-ea86-4080-8188-c8d717e9c3fe)\n",
            "\n",
            "Cannot access gated repo for url https://huggingface.co/meta-llama/Llama-3.2-1B/resolve/main/config.json.\n",
            "Access to model meta-llama/Llama-3.2-1B is restricted and you are not in the authorized list. Visit https://huggingface.co/meta-llama/Llama-3.2-1B to ask for access.\n",
            "\u001b[32m2025-06-16 20:27:57.648\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mattribute.caching\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m78\u001b[0m - \u001b[1mLoading model meta-llama/Llama-3.2-1B on device cuda\u001b[0m\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_http.py\", line 409, in hf_raise_for_status\n",
            "    response.raise_for_status()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/requests/models.py\", line 1024, in raise_for_status\n",
            "    raise HTTPError(http_error_msg, response=self)\n",
            "requests.exceptions.HTTPError: 403 Client Error: Forbidden for url: https://huggingface.co/meta-llama/Llama-3.2-1B/resolve/main/config.json\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/hub.py\", line 470, in cached_files\n",
            "    hf_hub_download(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_validators.py\", line 114, in _inner_fn\n",
            "    return fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\", line 1008, in hf_hub_download\n",
            "    return _hf_hub_download_to_cache_dir(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\", line 1115, in _hf_hub_download_to_cache_dir\n",
            "    _raise_on_head_call_error(head_call_error, force_download, local_files_only)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\", line 1645, in _raise_on_head_call_error\n",
            "    raise head_call_error\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\", line 1533, in _get_metadata_or_catch_error\n",
            "    metadata = get_hf_file_metadata(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_validators.py\", line 114, in _inner_fn\n",
            "    return fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\", line 1450, in get_hf_file_metadata\n",
            "    r = _request_wrapper(\n",
            "        ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\", line 286, in _request_wrapper\n",
            "    response = _request_wrapper(\n",
            "               ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\", line 310, in _request_wrapper\n",
            "    hf_raise_for_status(response)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_http.py\", line 426, in hf_raise_for_status\n",
            "    raise _format(GatedRepoError, message, response) from e\n",
            "huggingface_hub.errors.GatedRepoError: 403 Client Error. (Request ID: Root=1-68507e4d-104ccb9f6f9e4c1435fd5ee4;665cb332-06dc-4870-b6d7-42c725f59ce2)\n",
            "\n",
            "Cannot access gated repo for url https://huggingface.co/meta-llama/Llama-3.2-1B/resolve/main/config.json.\n",
            "Access to model meta-llama/Llama-3.2-1B is restricted and you are not in the authorized list. Visit https://huggingface.co/meta-llama/Llama-3.2-1B to ask for access.\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/queueing.py\", line 625, in process_events\n",
            "    response = await route_utils.call_process_api(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/route_utils.py\", line 322, in call_process_api\n",
            "    output = await app.get_blocks().process_api(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/blocks.py\", line 2220, in process_api\n",
            "    result = await self.call_function(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/blocks.py\", line 1731, in call_function\n",
            "    prediction = await anyio.to_thread.run_sync(  # type: ignore\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/anyio/to_thread.py\", line 56, in run_sync\n",
            "    return await get_async_backend().run_sync_in_worker_thread(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/anyio/_backends/_asyncio.py\", line 2470, in run_sync_in_worker_thread\n",
            "    return await future\n",
            "           ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/anyio/_backends/_asyncio.py\", line 967, in run\n",
            "    result = context.run(func, *args)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/utils.py\", line 894, in wrapper\n",
            "    response = f(*args, **kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/attribute/serve.py\", line 99, in generate\n",
            "    model_cache[model_name] = TranscodedModel(\n",
            "                              ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/attribute/attribute/caching.py\", line 84, in __init__\n",
            "    model = AutoModelForCausalLM.from_pretrained(\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/models/auto/auto_factory.py\", line 531, in from_pretrained\n",
            "    config, kwargs = AutoConfig.from_pretrained(\n",
            "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/models/auto/configuration_auto.py\", line 1153, in from_pretrained\n",
            "    config_dict, unused_kwargs = PretrainedConfig.get_config_dict(pretrained_model_name_or_path, **kwargs)\n",
            "                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/configuration_utils.py\", line 595, in get_config_dict\n",
            "    config_dict, kwargs = cls._get_config_dict(pretrained_model_name_or_path, **kwargs)\n",
            "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/configuration_utils.py\", line 654, in _get_config_dict\n",
            "    resolved_config_file = cached_file(\n",
            "                           ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/hub.py\", line 312, in cached_file\n",
            "    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/hub.py\", line 533, in cached_files\n",
            "    raise OSError(\n",
            "OSError: You are trying to access a gated repo.\n",
            "Make sure to have access to it at https://huggingface.co/meta-llama/Llama-3.2-1B.\n",
            "403 Client Error. (Request ID: Root=1-68507e4d-104ccb9f6f9e4c1435fd5ee4;665cb332-06dc-4870-b6d7-42c725f59ce2)\n",
            "\n",
            "Cannot access gated repo for url https://huggingface.co/meta-llama/Llama-3.2-1B/resolve/main/config.json.\n",
            "Access to model meta-llama/Llama-3.2-1B is restricted and you are not in the authorized list. Visit https://huggingface.co/meta-llama/Llama-3.2-1B to ask for access.\n",
            "\u001b[32m2025-06-16 20:28:05.427\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mattribute.caching\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m78\u001b[0m - \u001b[1mLoading model google/gemma-2-2b on device cuda\u001b[0m\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "05a94678bb6c4715aa97bcb16776fb36"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/queueing.py\", line 625, in process_events\n",
            "    response = await route_utils.call_process_api(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/route_utils.py\", line 322, in call_process_api\n",
            "    output = await app.get_blocks().process_api(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/blocks.py\", line 2220, in process_api\n",
            "    result = await self.call_function(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/blocks.py\", line 1731, in call_function\n",
            "    prediction = await anyio.to_thread.run_sync(  # type: ignore\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/anyio/to_thread.py\", line 56, in run_sync\n",
            "    return await get_async_backend().run_sync_in_worker_thread(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/anyio/_backends/_asyncio.py\", line 2470, in run_sync_in_worker_thread\n",
            "    return await future\n",
            "           ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/anyio/_backends/_asyncio.py\", line 967, in run\n",
            "    result = context.run(func, *args)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/utils.py\", line 894, in wrapper\n",
            "    response = f(*args, **kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/attribute/serve.py\", line 99, in generate\n",
            "    model_cache[model_name] = TranscodedModel(\n",
            "                              ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/attribute/attribute/caching.py\", line 84, in __init__\n",
            "    model = AutoModelForCausalLM.from_pretrained(\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/models/auto/auto_factory.py\", line 571, in from_pretrained\n",
            "    return model_class.from_pretrained(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\", line 309, in _wrapper\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\", line 4574, in from_pretrained\n",
            "    ) = cls._load_pretrained_model(\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\", line 4991, in _load_pretrained_model\n",
            "    caching_allocator_warmup(model_to_load, expanded_device_map, hf_quantizer)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\", line 6050, in caching_allocator_warmup\n",
            "    index = device.index if device.index is not None else torch.cuda.current_device()\n",
            "                                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py\", line 971, in current_device\n",
            "    _lazy_init()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py\", line 310, in _lazy_init\n",
            "    raise AssertionError(\"Torch not compiled with CUDA enabled\")\n",
            "AssertionError: Torch not compiled with CUDA enabled\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://8c00ed3685ed34e96c.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "import serve\n",
        "serve.default_config.batch_size = 8\n",
        "serve.default_config.flow_steps = 1000\n",
        "if not download_cache:\n",
        "    serve.default_config.use_self_explanation = True\n",
        "serve.main().launch(share=True, debug=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wt2CgALSZkCT"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d77323599e4048b1b912e2fbb378a4ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [],
            "layout": "IPY_MODEL_21e13a86ce17455bbcf1f08ff0b3c7d9"
          }
        },
        "856aeadbde0a473caf3ec3435e6bcb3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_48565c1db4ef4deca0154ae3f0a5bfcc",
            "placeholder": "​",
            "style": "IPY_MODEL_560b81b152c5400b857c4e54ee043bfb",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "37a4e49355fa45e194c7935489184651": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_9b1d97b7387e4a2093330d4b734d3832",
            "placeholder": "​",
            "style": "IPY_MODEL_e392e63fd17d4ca6ae367032b22babb2",
            "value": ""
          }
        },
        "6744bec188814e6c849fb6788004646a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_cb12395b76f444b8811e6a735d3229e5",
            "style": "IPY_MODEL_fb249295c05742cd849d1f35445268fd",
            "value": true
          }
        },
        "6ac901d815674f21a1dfbe6658465765": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_f38f60e36e98470894f46fccc81552d2",
            "style": "IPY_MODEL_26cf19232d764ed29527c29cd0022fad",
            "tooltip": ""
          }
        },
        "13e3f0d317254b64988018d5298f080d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f199f19bc67b43188ce5ded1ae1f78b1",
            "placeholder": "​",
            "style": "IPY_MODEL_05b1182539da40fc9ea6cb9b86e35d30",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "21e13a86ce17455bbcf1f08ff0b3c7d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "48565c1db4ef4deca0154ae3f0a5bfcc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "560b81b152c5400b857c4e54ee043bfb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9b1d97b7387e4a2093330d4b734d3832": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e392e63fd17d4ca6ae367032b22babb2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cb12395b76f444b8811e6a735d3229e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb249295c05742cd849d1f35445268fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f38f60e36e98470894f46fccc81552d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "26cf19232d764ed29527c29cd0022fad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "f199f19bc67b43188ce5ded1ae1f78b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "05b1182539da40fc9ea6cb9b86e35d30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2ab023a61ece409293710460e0afcae2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d0e30f10772a40ac83ece49e4172aca7",
            "placeholder": "​",
            "style": "IPY_MODEL_38f707461c814d5b8867735220b7849a",
            "value": "Connecting..."
          }
        },
        "d0e30f10772a40ac83ece49e4172aca7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "38f707461c814d5b8867735220b7849a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "396ace78a4d349119c0be34e8a16cb82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d47ee015c5864990a6f4ce5aa447341a",
              "IPY_MODEL_012cfeb33df642adbe600a4996319332",
              "IPY_MODEL_1a43cd89356c48f89ce2d24b9cfbc164"
            ],
            "layout": "IPY_MODEL_dfdc8bb3cacc4d7ea6f96963db6f9049"
          }
        },
        "d47ee015c5864990a6f4ce5aa447341a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0102a14c2c95416388e87c681b0f4fab",
            "placeholder": "​",
            "style": "IPY_MODEL_721589b2ba8649998efb462b3e881201",
            "value": "config.json: 100%"
          }
        },
        "012cfeb33df642adbe600a4996319332": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4ac834802d1940d8b54e9165cb3cd2b7",
            "max": 818,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0389d97bac96409ba2334fb653b6c40f",
            "value": 818
          }
        },
        "1a43cd89356c48f89ce2d24b9cfbc164": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_74c094602de149b0873dad499a7a843d",
            "placeholder": "​",
            "style": "IPY_MODEL_137a4d75b5624e76b88536ddbc977988",
            "value": " 818/818 [00:00&lt;00:00, 99.8kB/s]"
          }
        },
        "dfdc8bb3cacc4d7ea6f96963db6f9049": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0102a14c2c95416388e87c681b0f4fab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "721589b2ba8649998efb462b3e881201": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4ac834802d1940d8b54e9165cb3cd2b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0389d97bac96409ba2334fb653b6c40f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "74c094602de149b0873dad499a7a843d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "137a4d75b5624e76b88536ddbc977988": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c8b9e07926f64721b2d5e3c2ea14bf2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ee1833cbb24b4d61a0cd1d2bfdcaf9a0",
              "IPY_MODEL_7141cb9e6edd45669e429c1d9e88b4bf",
              "IPY_MODEL_b7f981986b9942fc93c7496ff56eeb20"
            ],
            "layout": "IPY_MODEL_91afd8de587c4e6583d06ecac36feea9"
          }
        },
        "ee1833cbb24b4d61a0cd1d2bfdcaf9a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_94113f287eab4116a1e769071c6f3c72",
            "placeholder": "​",
            "style": "IPY_MODEL_59483c64eb5941aba95d39b70216af20",
            "value": "model.safetensors.index.json: 100%"
          }
        },
        "7141cb9e6edd45669e429c1d9e88b4bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3a2676e1969f446696b22eee47556083",
            "max": 24224,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8c2ebcf302c4463db66404bf408cc3a5",
            "value": 24224
          }
        },
        "b7f981986b9942fc93c7496ff56eeb20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_717fd223f80547c9819768fc39e97380",
            "placeholder": "​",
            "style": "IPY_MODEL_6f6d001f779f4e71879ff828b90a2cf7",
            "value": " 24.2k/24.2k [00:00&lt;00:00, 3.26MB/s]"
          }
        },
        "91afd8de587c4e6583d06ecac36feea9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "94113f287eab4116a1e769071c6f3c72": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "59483c64eb5941aba95d39b70216af20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3a2676e1969f446696b22eee47556083": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c2ebcf302c4463db66404bf408cc3a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "717fd223f80547c9819768fc39e97380": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f6d001f779f4e71879ff828b90a2cf7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ea68b36948044fda93e34819e8bf7fe3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_aef827beb7504708b3d73c2c40e05257",
              "IPY_MODEL_ec30460532114a278511aad335930da2",
              "IPY_MODEL_549f9e05dbf34f4699b067f0fe3f2093"
            ],
            "layout": "IPY_MODEL_2293eb4fab564adbbab768f0f2d92abd"
          }
        },
        "aef827beb7504708b3d73c2c40e05257": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7001546681f04d19805864f47e29feae",
            "placeholder": "​",
            "style": "IPY_MODEL_88ee8b96da8d48dca8f8ab013abc2996",
            "value": "Fetching 3 files: 100%"
          }
        },
        "ec30460532114a278511aad335930da2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f7741a104a814a1b99f8f75f39b73e7d",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2d412f8be70d49ef933125f8d9bbd3df",
            "value": 3
          }
        },
        "549f9e05dbf34f4699b067f0fe3f2093": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2761a2936cea46e69925ac55540deeda",
            "placeholder": "​",
            "style": "IPY_MODEL_12f34a8a53254fdcafd6c8f86f14fbdb",
            "value": " 3/3 [00:54&lt;00:00, 54.57s/it]"
          }
        },
        "2293eb4fab564adbbab768f0f2d92abd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7001546681f04d19805864f47e29feae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "88ee8b96da8d48dca8f8ab013abc2996": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f7741a104a814a1b99f8f75f39b73e7d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d412f8be70d49ef933125f8d9bbd3df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2761a2936cea46e69925ac55540deeda": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12f34a8a53254fdcafd6c8f86f14fbdb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ad1848b50b1b4ac4beeac90e689042d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fd11d6285cf84ce38e61719adbad95dc",
              "IPY_MODEL_2273f7d44d994b57bd4b5019453941c2",
              "IPY_MODEL_2b193ed8953d4abeb5adee7aa8a07e18"
            ],
            "layout": "IPY_MODEL_dfd8302127af457c8eef51be3d97fd7d"
          }
        },
        "fd11d6285cf84ce38e61719adbad95dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0818671ff2f4483fa89112b8a897edba",
            "placeholder": "​",
            "style": "IPY_MODEL_a16e0fda54da42f6ab3c4d930765a8be",
            "value": "model-00001-of-00003.safetensors: 100%"
          }
        },
        "2273f7d44d994b57bd4b5019453941c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_259fb420875d471faf4746c5d57aae3e",
            "max": 4992576136,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2477e756b3fc4eb2ba425c8b13af3e35",
            "value": 4992576136
          }
        },
        "2b193ed8953d4abeb5adee7aa8a07e18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_949577afc3cf44f6bc62b2cbe65b5b01",
            "placeholder": "​",
            "style": "IPY_MODEL_618db6143ee142699e646380539d00f5",
            "value": " 4.99G/4.99G [00:54&lt;00:00, 120MB/s]"
          }
        },
        "dfd8302127af457c8eef51be3d97fd7d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0818671ff2f4483fa89112b8a897edba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a16e0fda54da42f6ab3c4d930765a8be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "259fb420875d471faf4746c5d57aae3e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2477e756b3fc4eb2ba425c8b13af3e35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "949577afc3cf44f6bc62b2cbe65b5b01": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "618db6143ee142699e646380539d00f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "90c238c080f94142956efac617c3387e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8fea3f3ec99f4cfbb063fa6a495ae909",
              "IPY_MODEL_6d4d5223d0504af180eb5752deee5c23",
              "IPY_MODEL_414233397b6f47d9b0cc4ff092a5bdb3"
            ],
            "layout": "IPY_MODEL_28e73d024c37439a82e0e19dc0bf6cdc"
          }
        },
        "8fea3f3ec99f4cfbb063fa6a495ae909": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc0555c1e2fb44dba77c8e1223f7695b",
            "placeholder": "​",
            "style": "IPY_MODEL_11c959768da147938a9c2f3920b964f8",
            "value": "model-00003-of-00003.safetensors: 100%"
          }
        },
        "6d4d5223d0504af180eb5752deee5c23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_561e0533016e4e0ca528b29b8084af90",
            "max": 481381384,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7f93abad431b4818a3b1bdc07349026b",
            "value": 481381384
          }
        },
        "414233397b6f47d9b0cc4ff092a5bdb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7ac29643164645c6828f11182536e583",
            "placeholder": "​",
            "style": "IPY_MODEL_1502165a0f40409bbc3efdb9d68ca2ff",
            "value": " 481M/481M [00:02&lt;00:00, 257MB/s]"
          }
        },
        "28e73d024c37439a82e0e19dc0bf6cdc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc0555c1e2fb44dba77c8e1223f7695b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "11c959768da147938a9c2f3920b964f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "561e0533016e4e0ca528b29b8084af90": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f93abad431b4818a3b1bdc07349026b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7ac29643164645c6828f11182536e583": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1502165a0f40409bbc3efdb9d68ca2ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "22ddc5cbda864c87b73d124442211828": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_74322ef1c78f4e7fa0935f5ec89fb26d",
              "IPY_MODEL_dd9b755a75934fab93a2429797d8319d",
              "IPY_MODEL_4fc35a9ca62041cb9ab62d12d3b3e489"
            ],
            "layout": "IPY_MODEL_346714ffa0c146ae8bec4e6a8e481d56"
          }
        },
        "74322ef1c78f4e7fa0935f5ec89fb26d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_40f3e8a018c4439885c9acc639f544d3",
            "placeholder": "​",
            "style": "IPY_MODEL_1a9ddedfe1574bfe902fedd36d88c458",
            "value": "model-00002-of-00003.safetensors: 100%"
          }
        },
        "dd9b755a75934fab93a2429797d8319d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_005811c29d80441682acd0b41334d4f3",
            "max": 4983443424,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e4c3cca56f5a4c4abca2bf3f00198f80",
            "value": 4983443424
          }
        },
        "4fc35a9ca62041cb9ab62d12d3b3e489": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_03fc5bf0694f4da9b226a86e9981508a",
            "placeholder": "​",
            "style": "IPY_MODEL_3b882f31b1084b87b2bb223d9a863384",
            "value": " 4.98G/4.98G [00:37&lt;00:00, 33.4MB/s]"
          }
        },
        "346714ffa0c146ae8bec4e6a8e481d56": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "40f3e8a018c4439885c9acc639f544d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a9ddedfe1574bfe902fedd36d88c458": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "005811c29d80441682acd0b41334d4f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e4c3cca56f5a4c4abca2bf3f00198f80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "03fc5bf0694f4da9b226a86e9981508a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b882f31b1084b87b2bb223d9a863384": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8cdbcfc5f12e4ea0a9652742c5bf4919": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_31ab43420e55409a88d80bfc052cb797",
              "IPY_MODEL_a1ad3b9777704962947f9189dbed976f",
              "IPY_MODEL_cb88149ca6c44433868d48f673a3aab3"
            ],
            "layout": "IPY_MODEL_f43e893304b84fe592d056f62244cf1c"
          }
        },
        "31ab43420e55409a88d80bfc052cb797": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8259034b887248af90300b3e873ae2eb",
            "placeholder": "​",
            "style": "IPY_MODEL_16301d26d736409889b4019a926fc060",
            "value": "Loading checkpoint shards:   0%"
          }
        },
        "a1ad3b9777704962947f9189dbed976f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fa5b89cc72b140b5a7b0a8789fe690e1",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_903c1532051c47a6b63ad7ec91f1d5d6",
            "value": 0
          }
        },
        "cb88149ca6c44433868d48f673a3aab3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b884f03d0b7e457d8582efbf4ca95d34",
            "placeholder": "​",
            "style": "IPY_MODEL_7697b6c607884cf085d7c09064907a06",
            "value": " 0/3 [00:00&lt;?, ?it/s]"
          }
        },
        "f43e893304b84fe592d056f62244cf1c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8259034b887248af90300b3e873ae2eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "16301d26d736409889b4019a926fc060": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fa5b89cc72b140b5a7b0a8789fe690e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "903c1532051c47a6b63ad7ec91f1d5d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b884f03d0b7e457d8582efbf4ca95d34": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7697b6c607884cf085d7c09064907a06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "05a94678bb6c4715aa97bcb16776fb36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5fd9e0925e624b9b9287ee1d751ed7c8",
              "IPY_MODEL_8fb5f9b2514f4af5ae57ef40c9b8a528",
              "IPY_MODEL_4b58efaabeb647348d906adc05772140"
            ],
            "layout": "IPY_MODEL_69935e09a8e842e2aa8677d97a36b8f2"
          }
        },
        "5fd9e0925e624b9b9287ee1d751ed7c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_77e62fc02d374f1aaa1e3b8dee6ae023",
            "placeholder": "​",
            "style": "IPY_MODEL_f9a1e6047c9a46ba9a6e854735081a08",
            "value": "Loading checkpoint shards:   0%"
          }
        },
        "8fb5f9b2514f4af5ae57ef40c9b8a528": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b0dbc5697ee44c4780e5cf44ce51a732",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3c4a22e189774ae8899dd542f7ea74ba",
            "value": 0
          }
        },
        "4b58efaabeb647348d906adc05772140": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f6c731d35f81477bab05c2dce4ce89a2",
            "placeholder": "​",
            "style": "IPY_MODEL_0b4b28d63fcb488bbe28a94e76d1e4aa",
            "value": " 0/3 [00:00&lt;?, ?it/s]"
          }
        },
        "69935e09a8e842e2aa8677d97a36b8f2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77e62fc02d374f1aaa1e3b8dee6ae023": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f9a1e6047c9a46ba9a6e854735081a08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b0dbc5697ee44c4780e5cf44ce51a732": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c4a22e189774ae8899dd542f7ea74ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f6c731d35f81477bab05c2dce4ce89a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b4b28d63fcb488bbe28a94e76d1e4aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}